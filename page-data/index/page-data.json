{"componentChunkName":"component---src-pages-index-js","path":"/","result":{"data":{"site":{"siteMetadata":{"title":"Gunu's AI Log","configs":{"countOfInitialPost":10}}},"allMarkdownRemark":{"edges":[{"node":{"excerpt":"í•´ë‹¹ í¬ìŠ¤íŠ¸ì— pytorchë¡œ ì½”ë“œë¥¼ ëŒë¦¬ë©´ì„œ ìƒê¸´ Runtime Errorë¥¼ ê¸°ë¡í•´ë³´ë ¤ê³  í•©ë‹ˆë‹¤!ğŸ˜Š ì—¬ëŸ¬ë¶„ë“¤ë„ ë˜‘ê°™ì€ Runtime Errorë¥¼ ê²ªê³  ê³„ì‹œë‹¤ë©´ ì°¸ê³ í•´ë³´ëŠ” ê²ƒë„ ì¢‹ì„ ê²ƒ ê°™ë„¤ìš”. ì•„ë˜ëŠ” ì´ë²ˆ í¬ìŠ¤íŠ¸ì˜ Categoryì…ë‹ˆë‹¤. Category Runtime Error Solutions Reference Runtime Error Solutionâ€¦","fields":{"slug":"/Pytorch/pytorch-error-solutions/"},"frontmatter":{"date":"September 08, 2021","title":"Pytorch Error Solutions","category":"Pytorch","draft":false}}},{"node":{"excerpt":"ì´ë²ˆ ì‹œê°„ì—ëŠ” pythonì˜ coding conventionì„ ë§ì¶°ì£¼ëŠ” 3ê°€ì§€ libraryì— ëŒ€í•´ì„œ ì•Œì•„ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤!ğŸ˜Š ì˜¤í”ˆ ì†ŒìŠ¤ í™˜ê²½ì—ì„œ, í˜‘ì—…ì„ í•˜ë‹¤ë³´ë©´ coding conventionì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ë‹¤ìˆ˜ì˜ ê°œë°œìê°€ ëª¨ì—¬ í˜‘ì—…ì„ í•˜ê¸° ë•Œë¬¸ì— ì„œë¡œê°€ ì½”ë“œë¥¼ ìˆ˜ì •í•˜ë”ë¼ë„ ì¼ê´€ì„± ìˆëŠ” ì½”ë“œë¥¼ ìƒì‚°í•´ ë‚´ëŠ” ê²ƒì´ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤. ì´ì— ê° ì–¸ì–´ ë³„ë¡œ ì´â€¦","fields":{"slug":"/Python/python-coding-convention-library/"},"frontmatter":{"date":"September 05, 2021","title":"Python Coding Convention Library","category":"Python","draft":false}}},{"node":{"excerpt":"ì´ë²ˆ ì‹œê°„ì—ëŠ” learning rate decayì— ëŒ€í•´ì„œ ì•Œì•„ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤!ğŸ˜† Learning rateëŠ” hyperparameterì¤‘ ê°€ì¥ ì¤‘ìš”í•˜ë‹¤ê³  ë§í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ learning rate ì— ë”°ë¼ì„œ í•™ìŠµì†ë„ê°€ ê²°ì •ë˜ë©° Global minimumìœ¼ë¡œ ìˆ˜ë ´í•  ìˆ˜ ìˆëŠëƒë¥¼ ê²°ì •í•˜ëŠ” ì¤‘ìš”í•œ ìš”ì†Œì…ë‹ˆë‹¤. ê·¸ë˜ì„œ ì˜¤ëŠ˜ì€ ì´ ì¤‘ìš”í•œ learning râ€¦","fields":{"slug":"/AI/learning-rate-decay/"},"frontmatter":{"date":"September 03, 2021","title":"Learning Rate Decay","category":"AI","draft":false}}},{"node":{"excerpt":"ì´ë²ˆ ì‹œê°„ì—ëŠ” Optimizationì— ëŒ€í•´ì„œ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤!âœŒ Deep learningì—ì„œëŠ” forwardì™€ back propagationì„ ë°˜ë³µí•˜ë©° í•™ìŠµì„ ì§„í–‰í•˜ê²Œ ë©ë‹ˆë‹¤. Loss functionì„ ì •ì˜í•˜ì—¬ forwardí•´ì„œ ë‚˜ì˜¨ ê²°ê³¼ ê°’ê³¼ labelê°’ì„ ë¹„êµí•˜ì—¬ Lossê°€ ì–¼ë§ˆì¸ì§€ ê³„ì‚°í•˜ê²Œ ë©ë‹ˆë‹¤. êµ¬í•œ Lossê°’ì„ í†µí•´ ìš°ë¦¬ëŠ” ìˆ˜ ë§ì€ weighâ€¦","fields":{"slug":"/AI/fancier-optimization/"},"frontmatter":{"date":"August 31, 2021","title":"Fancier Optimization","category":"AI","draft":false}}},{"node":{"excerpt":"ì´ë²ˆ ì‹œê°„ì—ëŠ” ì €ë²ˆ ì‹œê°„ì˜ Data Augmentation Linear Transformationì— ì´ì–´ì„œ Affine Transformationì— ëŒ€í•´ì„œ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤!ğŸ‘ ì´ì „ ì‹œê°„ì— Linear Transformationì€ ê¸°ì €ë²¡í„°ì˜ ë³€í˜•ì„ í†µí•´ ì´ë£¨ì–´ì§€ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì´ì „ì‹œê°„ì— ë°°ì› ë˜ ê°œë…ìœ¼ë¡œëŠ” translation(ì´ë™)ì„ ì„¤ëª…â€¦","fields":{"slug":"/AI/affine-transformation/"},"frontmatter":{"date":"August 30, 2021","title":"[Data Augmentation]Affine Transformation","category":"AI","draft":false}}},{"node":{"excerpt":"ì´ë²ˆ ì‹œê°„ì—ëŠ” imageë¥¼ augmentationí•  ìˆ˜ ìˆëŠ” ë°©ë²•ì¸ Linear Transfromationì— ëŒ€í•´ì„œ ì•Œì•„ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤!ğŸ™Œ Linear Transformationì— ëŒ€í•´ì„œ ì•Œê¸° ìœ„í•´ì„  ì•ì„œ í¬ìŠ¤íŒ… í–ˆë˜ Matrix Multiplicationì— ëŒ€í•œ ì§€ì‹ì´ ì„ í–‰ë˜ê¸° ë•Œë¬¸ì— ë³´ê³ ì™€ì£¼ì„¸ìš”~! ì•„ë˜ëŠ” ì´ë²ˆ í¬ìŠ¤íŒ…ì˜ Categoryì…ë‹ˆë‹¤. Catâ€¦","fields":{"slug":"/AI/linear-transformation/"},"frontmatter":{"date":"August 29, 2021","title":"[Data Augmentation] Linear Transformation","category":"AI","draft":false}}},{"node":{"excerpt":"ì´ë²ˆì‹œê°„ì—ëŠ” ë¨¸ì‹  ëŸ¬ë‹ ë¶„ì•¼ì—ì„œ ë§ì´ ì ‘í•  ìˆ˜ ìˆëŠ” Matrix Multiplicationì— ëŒ€í•´ ì•Œì•„ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤ğŸ˜ Matrix Multiplicationì€ í–‰ë ¬ê³±ì´ë¼ ë¶€ë¥´ë©° ë°©ì •ì‹ì„ í’€ ë•Œ ë§ì´ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ í–‰ë ¬ê³±ì„ ë²¡í„°ì˜ ë‚´ì ìœ¼ë¡œ ë³´ì•˜ì„ ë•Œ ì–´ë–»ê²Œ í•´ì„í•  ìˆ˜ ìˆëŠ”ì§€ ì•Œì•„ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤! ì•„ë˜ëŠ” ì´ë²ˆì‹œê°„ì— ì•Œì•„ë³¼ Matrix Multiplicâ€¦","fields":{"slug":"/Mathematics/matrix-multiplication/"},"frontmatter":{"date":"August 28, 2021","title":"Matrix Multiplication based on Geometry","category":"Mathematics","draft":false}}},{"node":{"excerpt":"ì´ë²ˆ ì‹œê°„ì—ëŠ” cross validationì— ëŒ€í•´ì„œ ì•Œì•„ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤!âœ¨ cross validationì€ í‰ìƒì‹œ ë°ì´í„°ê°€ ë¶€ì¡±í•  ë•Œ ì‚¬ìš©í•œë‹¤ê³ ë§Œ ì•Œê³  ìˆì—ˆëŠ”ë°, ì´ë²ˆì— ì œëŒ€ë¡œ ì•Œì•„ë³´ê³ ì ê³µë¶€í•´ë³´ì•˜ìŠµë‹ˆë‹¤ğŸ˜ What is Cross validation? Â  Â  ë³´í†µ í° ë°ì´í„° ì…‹ì´ ìˆë‹¤ë©´ ì‹¤ì œ ëª¨ë¸ì„ í‰ê°€í•˜ê¸° ìœ„í•´ì„œ ë°ì´í„°ë¥¼ í›ˆë ¨ìš©, ê²€ì¦ìš©, í…ŒìŠ¤íŠ¸ìš© â€¦","fields":{"slug":"/AI/cross-validation/"},"frontmatter":{"date":"August 26, 2021","title":"Cross Validation","category":"AI","draft":false}}},{"node":{"excerpt":"ì´ë²ˆ ì‹œê°„ì—ëŠ” Batch Normalizationì— ëŒ€í•´ì„œ ì•Œì•„ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤!ğŸ‘ ì´ì „ í¬ìŠ¤íŠ¸ì—ì„œ Xavier initializationì´ë‚˜ He initializationì´ ë¬´ì—‡ì¸ì§€, ì–´ë–¤ ì›ë¦¬ë¥¼ í†µí•´ ë§Œë“¤ì–´ ì¡ŒëŠ”ì§€ ì•Œì•„ë³´ì•˜ìŠµë‹ˆë‹¤. ì´ì— ìš°ë¦¬ëŠ” ì´ 2ê°œì˜ initialization ê¸°ë²•ì´ ê°ê°ì˜ layerì—ì„œ ë‚˜ì˜¤ëŠ” ê°ê°ì˜ activation valuâ€¦","fields":{"slug":"/AI/batch-normalization/"},"frontmatter":{"date":"August 22, 2021","title":"Batch Normalization","category":"AI","draft":false}}},{"node":{"excerpt":"ì´ë²ˆ ì‹œê°„ì—ëŠ” weight initializationì— ëŒ€í•´ì„œ ì•Œì•„ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤!ğŸ˜Š activation functionì„ sigmoidë¡œ ì‚¬ìš©í•˜ê²Œ ë˜ë©´ ì–‘ìª½ì˜ saturation area ë•Œë¬¸ì— gradient vanishing í˜„ìƒì´ ìƒê²¨ í•™ìŠµì´ ì˜ ë˜ì§€ ì•Šì„ ìˆ˜ê°€ ìˆì–´ì„œ ReLUë‚˜ Leaky ReLUë¥¼ ì‚¬ìš©í•˜ê²Œ ë©ë‹ˆë‹¤. í•˜ì§€ë§Œ ì´ activatioâ€¦","fields":{"slug":"/AI/weight-initialization/"},"frontmatter":{"date":"August 21, 2021","title":"Weight Initialization","category":"AI","draft":false}}},{"node":{"excerpt":"ì˜¤ëŠ˜ì€ Maximum Likelihood Estimation(MLE)ì´ë¼ê³  ë¶ˆë¦¬ëŠ” ìµœëŒ€ ìš°ë„ë²•ì— ëŒ€í•´ì„œ ì•Œì•„ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. MLEëŠ” í™•ë¥ ì„ ê¸°ë°˜í•œ ì¶”ì • ë¬¸ì œë¥¼ í•´ê²°í•  ë•Œ ì‚¬ìš©ë˜ëŠ” ì¶”ì • ë°©ë²•ì…ë‹ˆë‹¤. ëª©ì°¨ë¶€í„° ì‚´í´ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤ğŸ™‚ Category Definition of Maximum Likelihood Estimation(MLE) Likelihood â€¦","fields":{"slug":"/Mathematics/maximum-likelihood-estimation(mle)/"},"frontmatter":{"date":"August 19, 2021","title":"Maximum Likelihood Estimation(MLE)","category":"Mathematics","draft":false}}},{"node":{"excerpt":"ì´ë²ˆ ì‹œê°„ì—ëŠ” GANì— ëŒ€í•´ì„œ ì•Œì•„ë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. GANì€ Generative Adversarial Networksë¥¼ ì˜ë¯¸í•˜ë©° ì´ê²ƒì„ ì ëŒ€ì  ìƒì„± ì‹ ê²½ë§ì´ë¼ê³  ë¶€ë¦…ë‹ˆë‹¤. ë³¸ í¬ìŠ¤íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ì€ Categoryë¡œ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤. Category Discriminate Model & Generative Model Probability Density â€¦","fields":{"slug":"/AI/gan/"},"frontmatter":{"date":"August 12, 2021","title":"GAN","category":"AI","draft":false}}},{"node":{"excerpt":"ì´ë²ˆ ì‹œê°„ì—ëŠ” Linear Regression Modelì— ëŒ€í•´ì„œ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.\nLinear Regression Modelì€ ì„ í˜• íšŒê·€ ëª¨ë¸ë¡œ ë‹¤ìŒê³¼ ê°™ì€ Hypothesisë¥¼ ê°–ìŠµë‹ˆë‹¤. Category The Basic Description of Linear Regression Total Code Pandas Matplotlib The Basic Deâ€¦","fields":{"slug":"/AI/linear-regression-model/"},"frontmatter":{"date":"August 12, 2021","title":"Linear Regression Model","category":"AI","draft":false}}}]}},"pageContext":{}},"staticQueryHashes":["2486386679","3128451518"]}