{"componentChunkName":"component---src-templates-blog-post-js","path":"/Competition/[kaggle]digit-recognizer/","result":{"data":{"site":{"siteMetadata":{"title":"Gunu's AI Log","author":"[Gunu]","siteUrl":"https://gunu441.github.io","comment":{"disqusShortName":"","utterances":"gunu9441/gunu9441.github.io"},"sponsor":{"buyMeACoffeeId":"gunu9441"}}},"markdownRemark":{"id":"935c6669-9279-559e-a874-ca2c80dd27fb","excerpt":"이번 시간에는 Kaggle 입문자들이 Kaggle을 시작할 때 많이 해보는 Digit-Recognizer에 대해 이야기 해보려고 합니다!😊 많은 사람들이 Kaggle을 시작할 때 이 competition에 참가해보고 많은 notebook들을 보면서 딥러닝이나 머신러닝이 무엇이고 어떻게 해야하는지 알게되는데요! Digit-Recognizer은 MNIST data를 분류해보는 입문자용 competition…","html":"<p>    이번 시간에는 Kaggle 입문자들이 Kaggle을 시작할 때 많이 해보는 Digit-Recognizer에 대해 이야기 해보려고 합니다!😊 많은 사람들이 Kaggle을 시작할 때 이 competition에 참가해보고 많은 notebook들을 보면서 딥러닝이나 머신러닝이 무엇이고 어떻게 해야하는지 알게되는데요! Digit-Recognizer은 <strong>MNIST data를 분류</strong>해보는 입문자용 competition입니다. 이 대회를 하면서 <strong>구현 관점에서</strong> 알게되거나 느낀점을 바탕으로 해당 포스트를 작성하고자 합니다. 아래는 이번 포스팅의 Category입니다!</p>\n<h2 id=\"category\" style=\"position:relative;\"><a href=\"#category\" aria-label=\"category permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Category</h2>\n<ol>\n<li>Code Description</li>\n<li>History</li>\n<li>Summary</li>\n<li>Reference</li>\n</ol>\n<h2 id=\"code-description\" style=\"position:relative;\"><a href=\"#code-description\" aria-label=\"code description permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Code Description</h2>\n<h2 id=\"history\" style=\"position:relative;\"><a href=\"#history\" aria-label=\"history permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>History</h2>\n<p><strong>① version_1</strong></p>\n<p>사용한 Architecture는 다음과 같습니다.</p>\n<p>4<code class=\"language-text\">conv</code>- <code class=\"language-text\">batch</code> - <code class=\"language-text\">relu</code> , 1<code class=\"language-text\">pooling</code>, 3<code class=\"language-text\">fc layers</code></p>\n<p>    또한, <strong>He initilizationm</strong>과 <strong>batch normalization</strong>을 적용하여 구현을 하였습니다. <strong>4개의 convolution layer</strong>와 <strong>batchnorm</strong>, <strong>relu를 적용</strong>하였고 <strong>1번의 pooling을 사용</strong>했습니다. 또한 <strong>3개의 fc layer를 사용</strong>하고 <strong>2개의 dropout을 적용</strong>했습니다. 또한 <strong>early-stopping 기법을 사용</strong>했습니다.</p>\n<p>    또한 <strong>early stopping을 사용</strong>하여 <strong>model이 training data에 overfitting</strong>되는 것을 막았습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\">#conv1->batch1->relu->conv2->batch2->relu->pool->conv3->batch3->relu->conv4->batch4->relu</span>\n<span class=\"token comment\">#->fc1->relu->drop->fc2->relu->drop->fc3</span>\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">CNN</span><span class=\"token punctuation\">(</span>nn<span class=\"token punctuation\">.</span>Module<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>conv1 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span>  out_channels<span class=\"token operator\">=</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>conv2 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span><span class=\"token number\">16</span><span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>conv3 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span><span class=\"token number\">32</span><span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>conv4 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Conv2d<span class=\"token punctuation\">(</span>in_channels<span class=\"token operator\">=</span><span class=\"token number\">64</span><span class=\"token punctuation\">,</span> out_channels<span class=\"token operator\">=</span><span class=\"token number\">128</span><span class=\"token punctuation\">,</span> kernel_size<span class=\"token operator\">=</span><span class=\"token number\">3</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n\n        self<span class=\"token punctuation\">.</span>fc1 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span><span class=\"token number\">128</span><span class=\"token operator\">*</span><span class=\"token number\">8</span><span class=\"token operator\">*</span><span class=\"token number\">8</span><span class=\"token punctuation\">,</span><span class=\"token number\">1024</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>fc2 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span><span class=\"token number\">1024</span><span class=\"token punctuation\">,</span><span class=\"token number\">512</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>fc3 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Linear<span class=\"token punctuation\">(</span><span class=\"token number\">512</span><span class=\"token punctuation\">,</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span>\n\n        self<span class=\"token punctuation\">.</span>batchnorm1 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>BatchNorm2d<span class=\"token punctuation\">(</span><span class=\"token number\">16</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>batchnorm2 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>BatchNorm2d<span class=\"token punctuation\">(</span><span class=\"token number\">32</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>batchnorm3 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>BatchNorm2d<span class=\"token punctuation\">(</span><span class=\"token number\">64</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>batchnorm4 <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>BatchNorm2d<span class=\"token punctuation\">(</span><span class=\"token number\">128</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>drop <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>Dropout2d<span class=\"token punctuation\">(</span>p<span class=\"token operator\">=</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>max_pool <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>MaxPool2d<span class=\"token punctuation\">(</span>kernel_size<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> stride<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>relu <span class=\"token operator\">=</span> nn<span class=\"token punctuation\">.</span>ReLU<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token comment\">#initilization</span>\n        nn<span class=\"token punctuation\">.</span>init<span class=\"token punctuation\">.</span>kaiming_normal_<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>conv1<span class=\"token punctuation\">.</span>weight<span class=\"token punctuation\">,</span> mode<span class=\"token operator\">=</span><span class=\"token string\">'fan_in'</span><span class=\"token punctuation\">,</span> nonlinearity<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span>\n        nn<span class=\"token punctuation\">.</span>init<span class=\"token punctuation\">.</span>kaiming_normal_<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>conv2<span class=\"token punctuation\">.</span>weight<span class=\"token punctuation\">,</span> mode<span class=\"token operator\">=</span><span class=\"token string\">'fan_in'</span><span class=\"token punctuation\">,</span> nonlinearity<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span>\n        nn<span class=\"token punctuation\">.</span>init<span class=\"token punctuation\">.</span>kaiming_normal_<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>conv3<span class=\"token punctuation\">.</span>weight<span class=\"token punctuation\">,</span> mode<span class=\"token operator\">=</span><span class=\"token string\">'fan_in'</span><span class=\"token punctuation\">,</span> nonlinearity<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span>\n        nn<span class=\"token punctuation\">.</span>init<span class=\"token punctuation\">.</span>kaiming_normal_<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>conv4<span class=\"token punctuation\">.</span>weight<span class=\"token punctuation\">,</span> mode<span class=\"token operator\">=</span><span class=\"token string\">'fan_in'</span><span class=\"token punctuation\">,</span> nonlinearity<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span>\n        nn<span class=\"token punctuation\">.</span>init<span class=\"token punctuation\">.</span>kaiming_normal_<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>fc1<span class=\"token punctuation\">.</span>weight<span class=\"token punctuation\">,</span> mode<span class=\"token operator\">=</span><span class=\"token string\">'fan_in'</span><span class=\"token punctuation\">,</span> nonlinearity<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span>\n        nn<span class=\"token punctuation\">.</span>init<span class=\"token punctuation\">.</span>kaiming_normal_<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>fc2<span class=\"token punctuation\">.</span>weight<span class=\"token punctuation\">,</span> mode<span class=\"token operator\">=</span><span class=\"token string\">'fan_in'</span><span class=\"token punctuation\">,</span> nonlinearity<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span>\n        nn<span class=\"token punctuation\">.</span>init<span class=\"token punctuation\">.</span>kaiming_normal_<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>fc3<span class=\"token punctuation\">.</span>weight<span class=\"token punctuation\">,</span> mode<span class=\"token operator\">=</span><span class=\"token string\">'fan_in'</span><span class=\"token punctuation\">,</span> nonlinearity<span class=\"token operator\">=</span><span class=\"token string\">'relu'</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">forward</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>x<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token comment\">#x shape: 64*1*28*28</span>\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>conv1<span class=\"token punctuation\">(</span>x<span class=\"token punctuation\">)</span>\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>batchnorm1<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>relu<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n        <span class=\"token comment\">#64*16*26*26</span>\n\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>conv2<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>batchnorm2<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>relu<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n        <span class=\"token comment\">#64*32*24*24</span>\n\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>max_pool<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n        <span class=\"token comment\">#64*32*12*12</span>\n\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>conv3<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>batchnorm3<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>relu<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n        <span class=\"token comment\">#64*64*10*10</span>\n\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>conv4<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>batchnorm4<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>relu<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n        <span class=\"token comment\">#64*128*8*8</span>\n        <span class=\"token comment\">#flatten</span>\n        out <span class=\"token operator\">=</span> out<span class=\"token punctuation\">.</span>view<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">.</span>size<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span><span class=\"token operator\">-</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        <span class=\"token comment\">#64*128*8*8</span>\n\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>fc1<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>relu<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>drop<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>fc2<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>relu<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>drop<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span>\n\n        out <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>fc3<span class=\"token punctuation\">(</span>out<span class=\"token punctuation\">)</span></code></pre></div>\n<p><strong>① version_2</strong></p>\n<ol>\n<li>data augmentation 추가</li>\n</ol>\n<h2 id=\"summary\" style=\"position:relative;\"><a href=\"#summary\" aria-label=\"summary permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Summary</h2>\n<ol>\n<li>\n<p><code class=\"language-text\">transforms.ToPILImage()</code>를 사용하는 이유는 <strong>csv파일 형태로 데이터셋</strong>을 받을 경우, 바로 <code class=\"language-text\">torch.Tensor</code>로 바꿔줄 수 없기 때문입니다. <code class=\"language-text\">transforms.ToTensor()</code>는 <code class=\"language-text\">numpy.ndarray</code>나 <code class=\"language-text\">PIL image</code>를 <strong>pytorch tensor로 바꿔주기 때문</strong>에 <strong>csv에서 받은 dataframe</strong>을 <strong>PIL image로 바꿔주고 이 PIL image를 pytorch tensor로 바꿔주어야</strong>합니다. 이에 아래와 같이 작성합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> torchvision <span class=\"token keyword\">import</span> transforms\n\ntransfrom <span class=\"token operator\">=</span> transforms<span class=\"token punctuation\">.</span>compose<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n\t\t\t\ttransforms<span class=\"token punctuation\">.</span>ToPILImage<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n\t\t\t\ttransforms<span class=\"token punctuation\">.</span>ToTensor<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span></code></pre></div>\n</li>\n<li>\n<p>data를 어떻게 transform시킬지는 custom dataset을 초기화시킬 때, 인자로 넣어주는 것을 흔하게 볼 수 있었습니다. 아래의 그림처럼 말이죠!😎</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">MNIST_data</span><span class=\"token punctuation\">(</span>Dataset<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\t\t<span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span>\n\t\t\t\t\t\t\t\t file_path<span class=\"token punctuation\">,</span>\n\t\t             transform <span class=\"token operator\">=</span> transforms<span class=\"token punctuation\">.</span>Compose<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>transforms<span class=\"token punctuation\">.</span>ToPILImage<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t transforms<span class=\"token punctuation\">.</span>ToTensor<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n\t\t                         transforms<span class=\"token punctuation\">.</span>Normalize<span class=\"token punctuation\">(</span>mean<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> std<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\t\t              <span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span></code></pre></div>\n</li>\n<li>early stopping은 training set에 대한 오류가 줄어들지만 validation set에 대한 loss 올라가게 되면 멈추는 것을 의미합니다. <strong>① version_1</strong>에서 해당 기법을 추가시켰습니다.</li>\n<li>batchnorm이랑 dropout을 섞어쓰면 오히려 <strong>성능이 저하</strong>된다고 합니다😅</li>\n<li><code class=\"language-text\">np.arange(1,len(test_data)+1)</code>을 통해 쉽게 csv의 column을 만들 수 있었습니다~!</li>\n<li>\n<p>torch→numpy로 변환할 땐 <code class=\"language-text\">. numpy()</code>를, Dataframe→numpy로 변환할 땐 <code class=\"language-text\">.values</code> 대신에 <code class=\"language-text\">.to_numpy()</code>를 사용합니다. <code class=\"language-text\">.values</code>는 <strong>deprecate</strong>(비추천!)한다고 하더라구요!<br>\n또한, numpy를 torch.Tensor로 바꾸기 위해선 <code class=\"language-text\">torch.from_numpy()</code>를 사용합니다. 이 경우, <strong>shape는 유지</strong>한 채로 <strong>type만 변환</strong>됩니다!</p>\n<p align=\"center\">\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 550px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 32.666666666666664%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsTAAALEwEAmpwYAAAA2ElEQVQoz6WQ4U6EMBCEef/HU0+Ow3JACxySpbSlJ1cI44Ix/jFn1CZfOtnMTiYbkR1AvQbpAd0wQhsHO/rf40b46xuipE5xEDFikeLhVEI1LZz/MjrGsHmw7kc2b/RcJTicYyRngae0YN3iWLRIUoGsVHjMGjQd7eHb0hb+HXugvyKSVCPvJIpaob68orwQXiqCqDoUUkHkOZ+ih7H3W2pjPxoaFp6T52XBPDPLzP8nyz4PrEO4zy2E3R9VlUKWZZBSQjFaa/zncUODvu93iAjTNGFd1z/zDoG8GVm6K21fAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"assets 2021 09 10 1\" title=\"assets 2021 09 10 1\" src=\"/static/a344836a467003ad763b3fbc69d87cd6/dd45a/1.png\" srcset=\"/static/a344836a467003ad763b3fbc69d87cd6/5a46d/1.png 300w,\n/static/a344836a467003ad763b3fbc69d87cd6/dd45a/1.png 550w\" sizes=\"(max-width: 550px) 100vw, 550px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span>\n</p>\n</li>\n<li>\n<p>matplolib이나 cv2의 경우, <code class=\"language-text\">numpy.ndarray</code>를 많이 사용합니다. 이 때, <code class=\"language-text\">numpy.ndarray</code>들의 format은 HWC인데 torch.Tensor의 경우 CHW의 format을 갖습니다. 따라서 HWC인 numpy.ndarray들을 CHW format을 갖고 있는 troch.Tensor로 바꿔주기 위해서 <code class=\"language-text\">torchvision.transfroms.ToTensor()</code>를 사용합니다. 따라서, shape를 바꿔주기 위해선 6.의 <code class=\"language-text\">torch.from_numpy()</code>를 사용하는 것이아니라 <code class=\"language-text\">ToTensor()</code>를 사용해야합니다.</p>\n<p align=\"center\">\n    <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 552px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 38.33333333333333%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA10lEQVQoz52Py26DMBBF/f/fBwnGrrFDcVoBMX52geDGeBF1VxpLR3ckS2fuEOcCrPNwPsId6RyM9ZhtKGl9gI8pE0+QQKjiqOgF9MpRtwoVkxi+viHuBp0eMT1MkS552RkIv3dgnwKNalFTBi5veCwLfMjNQnzJjvyLImy6Fg3juDYUVfuBmgvI/gZTNp6XvYRiVGD6aMjyySI3HEqzsyf+xlgHMi8mt7HwKSJkUUwp8/M2RA8DpnHEPM2w1ha2bcO7jyiloLVG3/eQUpZ5Xdfyue/7v3kCKS9jtqJ6aLMAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"assets 2021 09 10 2\" title=\"assets 2021 09 10 2\" src=\"/static/723843f6a6779f991b69b97d0b4131b4/08c0b/2.png\" srcset=\"/static/723843f6a6779f991b69b97d0b4131b4/5a46d/2.png 300w,\n/static/723843f6a6779f991b69b97d0b4131b4/08c0b/2.png 552w\" sizes=\"(max-width: 552px) 100vw, 552px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span>\n</p>\n<p>또한 아래와 같은 방법으로 <code class=\"language-text\">torchvision.transfroms.ToTensor()</code>을 사용할 수 있습니다.</p>\n<p align=\"center\">\n    <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 546px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 36%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsTAAALEwEAmpwYAAAAzUlEQVQoz52Q266CMBBF+/9/Z4wBpSJHEBpT7Ewv+Ma2rZf4YsQzycrMw2TPakWYrtBsMBoDPRqcyePCDj4EOB8J070vRJCzKPsK5XGHYr/Dqtij7c9g50HWwbB9zUsQ7Bw2ssDh2GIrJdalRNX8oVGE+qTRDwr1oYkvIFjvc/gnciDFwGzYVihkNCxr1G2XF5Ld03KJXdoT6a8uRDCWwSFeYkaYJvhEePA+f0GkAKUURq3BxLDWIsQj/60cOAxDDk296zpQNE41z/PP3AAPuhgvN/SoxgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"assets 2021 09 10 3\" title=\"assets 2021 09 10 3\" src=\"/static/1aedd44d43e5653877b29080ae324bd7/76aed/3.png\" srcset=\"/static/1aedd44d43e5653877b29080ae324bd7/5a46d/3.png 300w,\n/static/1aedd44d43e5653877b29080ae324bd7/76aed/3.png 546w\" sizes=\"(max-width: 546px) 100vw, 546px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span>\n</p>\n</li>\n<li><code class=\"language-text\">plt.scatter()</code>을 사용하면 <strong>점</strong>으로, <code class=\"language-text\">plt.plot</code>을 사용하면 <strong>그래프</strong>로 그려집니다!</li>\n<li><code class=\"language-text\">cv2.imread</code>는 이미지를 받아 <code class=\"language-text\">numpy.ndarray</code>로 반환합니다. 따라서 csv파일을 읽을 때, cv2로 image를 읽은 듯한 효과를 주기 위해선 pandas의 <code class=\"language-text\">read_csv</code>를 사용하여 DataFrame으로 이미지를 읽은 후 <code class=\"language-text\">to_numpy()</code>를 통해 <code class=\"language-text\">numpy.ndarray</code>로 바꿔주면 됩니다. 즉, 평상시에 이미지를 읽을 때 <code class=\"language-text\">numpy.ndarray</code>로 읽으므로 DataFrame을 받게되면 이것 또한 <code class=\"language-text\">numpy.ndarray</code>로 바꿔서 <strong>data augmentation</strong>(albumentation을 통해)을 수행하면 됩니다. albumentation을 사용할 경우, <code class=\"language-text\">numpy.ndarray</code></li>\n<li>Albumentation은 <code class=\"language-text\">cv2.imread</code>를 통해 image를 <code class=\"language-text\">numpy.ndarray</code>로 읽어 data augmentation을 수행합니다. <code class=\"language-text\">cv2.imread</code>를 통해 읽게 되면 <code class=\"language-text\">HWC format</code>을 가진 <code class=\"language-text\">numpy.ndarray</code>를 받게 되는데 Albumentation은 <code class=\"language-text\">HWC format</code>을 가진 <code class=\"language-text\">numpy.ndarray</code>를 그대로 받아 <strong>data augmentation을 수행</strong>합니다. 또한 <code class=\"language-text\">matplotlib.pyplot.imshow()</code>는 argument로 <code class=\"language-text\">numpy.ndarray</code>를 받는데 이 떄의 format 또한 <code class=\"language-text\">HWC format</code>이 됩니다.\n즉, <code class=\"language-text\">Albumentations</code>, <code class=\"language-text\">matplotlib</code>, <code class=\"language-text\">cv2</code>는 <code class=\"language-text\">HWC format</code>을 가지는 <code class=\"language-text\">numpy.ndarray</code>을 다룹니다. 따라서 torch.Tensor에서의 이미지는 <code class=\"language-text\">CHW format</code>이므로 순서를 바꿔줘야합니다. 이에<code class=\"language-text\">torchvision.transfroms.ToTensor()</code>을 사용해야한다고 말했었죠?!😉</li>\n<li>\n<p><code class=\"language-text\">np.repeat(ndarray, 반복 횟수, axis=)</code>을 통해 image차원을 늘려줄 수 있습니다. MNIST 데이터의 경우 1차원일 땐 이상한 색이 나오게 되지만 <code class=\"language-text\">image = np.repeat(image,3,axis=2)</code>을 사용해서 3차원으로 늘리게 되면 익숙한 하얀색 숫자가 나오게 됩니다. 아래의 그림들 처럼 출력되게 됩니다.</p>\n<p align=\"center\">\n    <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 221px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 100.4524886877828%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEL0lEQVQ4y21UbUybVRR+Cwy/ovtDxABihmQSNq3JQGkpbaFfUDYG9Lt8rDTAmESD2RKzxDhNRGMmzk1RUWFKbMPopMDWySaJxsUfxrjFuamogwnt+FhwA5TR8fF47m3pVtib3J639577vOec5zlHmL85j99//gO9bT6c6BjAifb1q3/NWufTcRo9H53ElaFRCMtYQufBLjwt5CNX2A6JoI9auUIRZEIht2xJaa332Y6nBAUHFUBP/6cDdGkHCuOt0MaaQ2uDGTqRAQrBRhcqkCeyQSnYoRVMKIw1QBtnjviyezICZZFywOOtfXSpmA5NUIuMUMcYoBKMkG90oFFrQ+Vru1HbXo2KA7uhzGmgKCuhEcrIz8j9GSiLlKUvBJeDcB/y8LA1DJCcNEI5lBl1aHEZ8W8gHUvXNgEzj2JyMh1fXZShaa8d8gfroQ6DRgGyCHs/PkVf1YfSICfJQ3XY3+4A/ksCppIxF9gM77dFuDiSBVxPBP55DC2fGyHZWMP92b0oQFZMKUs53kyplkJh2YNz489i4q9MHPyuDBWtjdiW9RJ2yhxo7SvB0nQqhie2QlH5HC8Nq3cEcHj0Mrrf7+WAug1G5FHhXzhgAxaT8errDmxJ2wtJnI0TlC8YsC3veXx9Np+iTMaLnmpkJ9SiiEoUFaG3LRShPqYUT97bCFenAcFgEpw7GLPEIu2rqFa6+DL6oA27KqpwazYF7vM6ZGU6CdCwFtBHpOipyCYUb67CD2efweSNDOwqqyLZWKEmmTA2VbGUHpUkZ0sdBs6pMTO+CTVyC33UyjXKAa/4R+ChlBkgO3BqLBgLZACzSXjFakcOaVAbVx4CjDFBJ5RAet8e+Dx6Iu0R7NOYSIP224B3kqInxsSJDWg7XUrOD+OdjhLIEkJMaigyrWgnRWyBVlGPP4fE+P4XKTRb2bmRq+S2bCjlVVJYZzgbHfBPZ2L2WhpePmZFdmoT5PfXQnZPPbTKBnzyTTGwkIJ9zUbKoBqFcXfUcGRsGN3veTmghuuwFNIHnGhqrcDKVCpujKdjcFANb7cKnq4CXPg1m8qRiB+HciEhxpl/lGzYcPjyg/6QDqlTGJvMKTuhHi395Vi8ngbMJQM3SeTzZKdTcP6CGCZjLQpEdt6md+kUXxjQHO7lUPupHq+BdX8jzvgk8A8+gTOncuGsqYY1k5FgD/Xz2l72T/jhoeFwt2nDJoucalogskAjMnPLhK8ibbJ68xLFhaYNmwUn2bQJLi2g+4gX4vA8ZGxJw3OOWRm3ReG5VxyZiSyjVb88CkYsKNHzYXgeXvrpNxxtdsFzpA+utz3ofKsL3Yd74W45jqNvuPh716EedDR/we2xd718n/l6Dvfhszfd9N+Ny5dGQoAzczNYwTJWn+DyAreLuIWrU4HIfmDSH3kfvfo3/a7wd//EWGT/f3xom0KzNyC2AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"assets 2021 09 10 4\" title=\"assets 2021 09 10 4\" src=\"/static/413579637cc3d490f38245c9f3bd7ba3/cccdc/4.png\" srcset=\"/static/413579637cc3d490f38245c9f3bd7ba3/cccdc/4.png 221w\" sizes=\"(max-width: 221px) 100vw, 221px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span>\n</p>\n<p align=\"center\">\n    <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 226px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 97.34513274336283%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAATCAYAAACQjC21AAAACXBIWXMAAAsTAAALEwEAmpwYAAACqklEQVQ4y6VUPUiyURR+K60InQQh0DKHIhzUiMbcjNoLkcYgykyTkqZySuzHnymitaW5oaCGhpyKoAYhWiLIcvBf0iF6vu+cuPfzzb6pA+e99z33nufe89znXqVer+Pg4ACDg4MYGRmBw+FocYqTO53OljGK2Ww2TExMoFqtQsFf297ehqIov3KDwYBSqfQFmEqlOKjVatHe3s4uJnZ1dfFOxsfHYTKZZLyjo4PnUUv/fX19KJfLUD4+PhCNRjnYDNTT04P5+XlcXV3h+fkZb29vSKfTCIfD0Ov1PKetrY2d+rQYA9IO4/G4XFUAbmxs4H92enqKoaEhVY4KMJlMypKpdbvdyOVynFypVBjA4/Hg6OiIiSc7OTlhOsQGJCAl7u7uqgBjsRgnHR4eYnJyEgMDAzJxf3+fx/L5PKampmTcbDb/4zCRSEgONRoNzs7OOImkIhIEVzqdDufn5zy+s7PTCthcMnlvby/u7+9Rq9UwPDys4km0y8vLDEgLi6okYLFYlCWTz8zM8OTPz0+MjY2pTl+0drsd7+/veHh4YDWoABuNhiyZnDSXzWYZ1Ov1SiBBB/0Tr7Tg5eVl6w6bhS0S6DDICHh2dlZ1I4jXu7s7Hp+enm7lkD6CXAFIGru5ueGkp6cnFv76+jo2NzeRyWQ4fnt7y9etRTb02dvbk6WJ0xwdHZVa/G6Pj49wuVwqXlXCFiWLQQFKXB0fH+Pl5QWFQgHX19dYW1tjnr/LSQKSPMTV6+zsZGlQ6aL87u5u9Pf3w2q1wmg0SiA6DJojDsVisXwB0tXa2tr69fNFD4Z8vi4uLjA3N4fV1VX4/X74fD6EQiEsLS1hcXGR44FAAAsLCxwnYdNLtLKygmAwyLmRSAT0WCviAfjJSLxijK4o7UDY6+ur7Dcf3h/b+Ci9jEAHRQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"assets 2021 09 10 5\" title=\"assets 2021 09 10 5\" src=\"/static/54cc15270e99f3898f6968c2448093fc/5f7d4/5.png\" srcset=\"/static/54cc15270e99f3898f6968c2448093fc/5f7d4/5.png 226w\" sizes=\"(max-width: 226px) 100vw, 226px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span>\n</p>\n</li>\n<li><code class=\"language-text\">import Albumentations.pytorch.transforms.ToTensor()</code>를 통해 pytorch tensor로 변환가능합니다.</li>\n<li>하나의 dataset객체 안에서 valid datset과 training dataset을 못나눔. dataloader를 통해서 뽑아줄 방법이 없음. 데이터를 나눠놔도 뽑아올 방법이없음…</li>\n</ol>\n<h2 id=\"todo\" style=\"position:relative;\"><a href=\"#todo\" aria-label=\"todo permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Todo</h2>\n<ul>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> albumentation으로 augmentation 전처리해보기</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> vscode로 .py로 나눠서 모델 돌려보기</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> Ray-tune으로 Hyperparameter tuning해보기</li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> 내장함수 찾아보기 <strong>len</strong>, <strong>getitem</strong></li>\n<li class=\"task-list-item\"><input type=\"checkbox\" disabled> image(matplotlib과 Albumentation은 numpy 배열기준으로 HWC로 작동함 아마 cv2.imread도 HWC순서대로 읽는듯?)는 HWC순이고 pytorch tensor는 CHW인지 확인하기</li>\n</ul>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<ol>\n<li><code class=\"language-text\">transforms.ToPILImage()</code>를 왜 사용하는가?: <a href=\"https://green-late7.tistory.com/56\">https://green-late7.tistory.com/56</a></li>\n<li>numpy stack 방법(concatenate): <a href=\"https://rfriend.tistory.com/352\">https://rfriend.tistory.com/352</a></li>\n<li>Reference notebook: <a href=\"https://www.kaggle.com/juiyangchang/cnn-with-pytorch-0-995-accuracy/output\">https://www.kaggle.com/juiyangchang/cnn-with-pytorch-0-995-accuracy/output</a></li>\n<li>albumentation vs torchvision: <a href=\"https://pseudo-lab.github.io/Tutorial-Book/chapters/object-detection/Ch3-preprocessing.html\">https://pseudo-lab.github.io/Tutorial-Book/chapters/object-detection/Ch3-preprocessing.html</a></li>\n<li>kaggle csv파일 제출하기: <a href=\"https://wikidocs.net/92861\">https://wikidocs.net/92861</a></li>\n<li>model 저장 및 불러오기: <a href=\"https://tutorials.pytorch.kr/beginner/saving_loading_models.html\">https://tutorials.pytorch.kr/beginner/saving<em>loading</em>models.html</a></li>\n<li>early-stopping github code: <a href=\"https://github.com/Bjarten/early-stopping-pytorch/blob/master/MNIST_Early_Stopping_example.ipynb\">https://github.com/Bjarten/early-stopping-pytorch/blob/master/MNIST<em>Early</em>Stopping_example.ipynb</a></li>\n<li>score 올리는 법:<a href=\"https://wegonnamakeit.tistory.com/9\">https://wegonnamakeit.tistory.com/9</a></li>\n<li><code class=\"language-text\">DataFrame.to_numpy()</code>: <a href=\"https://stackoverflow.com/questions/13187778/convert-pandas-dataframe-to-numpy-array/\">https://stackoverflow.com/questions/13187778/convert-pandas-dataframe-to-numpy-array/</a></li>\n<li><code class=\"language-text\">plt.subplots(nrows=,ncols=,figsize=)</code>사용법: <a href=\"https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html\">https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html</a></li>\n<li><code class=\"language-text\">np.repeat()</code>: <a href=\"https://numpy.org/doc/stable/reference/generated/numpy.repeat.html\">https://numpy.org/doc/stable/reference/generated/numpy.repeat.html</a></li>\n<li>image augmentation using albumentation youtube: <a href=\"https://www.youtube.com/watch?v=n_f6d4bPFME\">https://www.youtube.com/watch?v=n_f6d4bPFME</a></li>\n<li>albumentation probability in One of Block and description about it: <a href=\"https://albumentations.readthedocs.io/en/latest/probabilities.html\">https://albumentations.readthedocs.io/en/latest/probabilities.html</a></li>\n<li>albumentation 간단 소개: <a href=\"https://hoya012.github.io/blog/albumentation_tutorial/\">https://hoya012.github.io/blog/albumentation_tutorial/</a></li>\n<li>albumentation documentation example: <a href=\"https://albumentations.ai/docs/examples/example/#Import-the-required-libraries\">https://albumentations.ai/docs/examples/example/#Import-the-required-libraries</a></li>\n<li>torchvision.transforms vs albumentation: <a href=\"https://pseudo-lab.github.io/Tutorial-Book/chapters/object-detection/Ch3-preprocessing.html\">https://pseudo-lab.github.io/Tutorial-Book/chapters/object-detection/Ch3-preprocessing.html</a></li>\n<li>albumentation 자세한 소개: <a href=\"https://ichi.pro/ko/albumentation-sijaghagi-pytorch-yejeeseo-dib-leoning-imiji-hwagdae-gibeob-hoegdeug-78798591550456\">https://ichi.pro/ko/albumentation-sijaghagi-pytorch-yejeeseo-dib-leoning-imiji-hwagdae-gibeob-hoegdeug-78798591550456</a></li>\n<li>albumentation.pytorch.ToTensorV2 documentation: <a href=\"https://albumentations.ai/docs/api_reference/pytorch/transforms/\">https://albumentations.ai/docs/api_reference/pytorch/transforms/</a></li>\n</ol>","frontmatter":{"title":"Digit Recognizer","date":"September 10, 2021"}}},"pageContext":{"slug":"/Competition/[kaggle]digit-recognizer/","previous":{"fields":{"slug":"/Pytorch/pytorch-error-solutions/"},"frontmatter":{"title":"Pytorch Error Solutions"}},"next":{"fields":{"slug":"/AI/google-cloud-platform(gcp)/"},"frontmatter":{"title":"Google Cloud Platform(GCP)"}}}},"staticQueryHashes":["2486386679","3128451518"]}