{"componentChunkName":"component---src-templates-blog-post-js","path":"/AI/weight-initialization/","result":{"data":{"site":{"siteMetadata":{"title":"Gunu's AI Log","author":"[Gunu]","siteUrl":"https://gunu441.github.io","comment":{"disqusShortName":"","utterances":"gunu9441/gunu9441.github.io"},"sponsor":{"buyMeACoffeeId":"gunu9441"}}},"markdownRemark":{"id":"7d1a2426-4743-5fc2-9524-bcd1d4a27b64","excerpt":"이번 시간에는 weight initialization에 대해서 알아보도록 하겠습니다!😊 activation function을 sigmoid로 사용하게 되면 양쪽의 saturation area 때문에 gradient vanishing 현상이 생겨 학습이 잘 되지 않을 수가 있어서 ReLU나 Leaky ReLU를 사용하게 됩니다. 하지만 이 activation function을 잘 설정해도 아래 그림처럼 매번 학습되는 속도(cost…","html":"<p>    이번 시간에는 weight initialization에 대해서 알아보도록 하겠습니다!😊 activation function을 sigmoid로 사용하게 되면 양쪽의 saturation area 때문에 gradient vanishing 현상이 생겨 학습이 잘 되지 않을 수가 있어서 <strong>ReLU나 Leaky ReLU를 사용</strong>하게 됩니다. 하지만 이 activation function을 잘 설정해도 아래 그림처럼 매번 학습되는 속도(cost가 떨어지는 속도)가 달라지거나 학습이 되지 않을 수 있는데 이는 weight initialization의 영향일 수 있습니다.</p>\n<p align=\"center\">\n   <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 842px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 56.333333333333336%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAABXUlEQVQoz3VSa2/DIAzs//9vW1dNqvph2qe1U5ssTUgaMC/vDOQ1dUiXM2AuZ8wuxsjLiCyzac05x9baFHvvc0bZE4ornsZOPkTEwzDwnFlSVNvy++HAp+OR3/b7hP3rCw9KbXPBsWA3/VEciCPjAt+14w5Q5ME2QSUmVsZybxw/rOcHZR6BEAIEwyJojGFLhhsInXviHmItDipAYhEZwBkuQfvIl9sPnz4+uSuuZ0GtDRNENRzWD0IZYYuwxHEVh1SZLQ7j2iEllx4bNwj2RpKQjAOyJleSEbZc9kRQsAiiMeLQIlHKkTtz4oQ5Ja4PTXEW+0dQOk20CEryd9NxVVW5nAlzyXFek0qeCFo4pCTUwp0cHEbN5/qOpjh0ckLubuIy18+6LE9GXMrcODwXdPXrWvOlalJc4V7rseBP3IBnwXxHMXVXytBaswE03Ck8hbbtEI8b5P3tXJoq4xeIcl2oZWV4gQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"assets 2021 08 21 1\" title=\"assets 2021 08 21 1\" src=\"/static/df5d1e72962f0adc6f95043f445293ba/99072/1.png\" srcset=\"/static/df5d1e72962f0adc6f95043f445293ba/5a46d/1.png 300w,\n/static/df5d1e72962f0adc6f95043f445293ba/0a47e/1.png 600w,\n/static/df5d1e72962f0adc6f95043f445293ba/99072/1.png 842w\" sizes=\"(max-width: 842px) 100vw, 842px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span>\n</p>\n<p>    이번 포스트의 카테고리는 다음과 같습니다.</p>\n<h2 id=\"category\" style=\"position:relative;\"><a href=\"#category\" aria-label=\"category permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Category</h2>\n<ol>\n<li>The Basic Concept of Weight Intilization</li>\n<li>Weight Initialization Problems</li>\n<li>Weight Initialization Methods</li>\n<li>More Details about Xavier Initialization &#x26; He Initialization</li>\n<li>Code</li>\n<li>Summary</li>\n<li>Reference</li>\n</ol>\n<h2 id=\"the-basic-concept-of-weight-initialization\" style=\"position:relative;\"><a href=\"#the-basic-concept-of-weight-initialization\" aria-label=\"the basic concept of weight initialization permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>The Basic Concept of Weight Initialization</h2>\n<p align=\"center\">\n   <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 842px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 56.333333333333336%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAABXUlEQVQoz3VSa2/DIAzs//9vW1dNqvph2qe1U5ssTUgaMC/vDOQ1dUiXM2AuZ8wuxsjLiCyzac05x9baFHvvc0bZE4ornsZOPkTEwzDwnFlSVNvy++HAp+OR3/b7hP3rCw9KbXPBsWA3/VEciCPjAt+14w5Q5ME2QSUmVsZybxw/rOcHZR6BEAIEwyJojGFLhhsInXviHmItDipAYhEZwBkuQfvIl9sPnz4+uSuuZ0GtDRNENRzWD0IZYYuwxHEVh1SZLQ7j2iEllx4bNwj2RpKQjAOyJleSEbZc9kRQsAiiMeLQIlHKkTtz4oQ5Ja4PTXEW+0dQOk20CEryd9NxVVW5nAlzyXFek0qeCFo4pCTUwp0cHEbN5/qOpjh0ckLubuIy18+6LE9GXMrcODwXdPXrWvOlalJc4V7rseBP3IBnwXxHMXVXytBaswE03Ck8hbbtEI8b5P3tXJoq4xeIcl2oZWV4gQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"assets 2021 08 21 1\" title=\"assets 2021 08 21 1\" src=\"/static/df5d1e72962f0adc6f95043f445293ba/99072/1.png\" srcset=\"/static/df5d1e72962f0adc6f95043f445293ba/5a46d/1.png 300w,\n/static/df5d1e72962f0adc6f95043f445293ba/0a47e/1.png 600w,\n/static/df5d1e72962f0adc6f95043f445293ba/99072/1.png 842w\" sizes=\"(max-width: 842px) 100vw, 842px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span>\n</p>\n<p>    우리가 모델을 알맞게 설정하고 activation function을 잘 선택해도 위에 봤던 그림처럼 매번 학습되는 속도(cost가 떨어지는 속도)가 달라지게 됩니다. 이는 weight initialization을 해주지 않고 weight 값을 random하게 주기 때문입니다. 따라서 어떻게 weight 값을 초기화해주며 종류에는 무엇이 있는지 알아보도록 하겠습니다.</p>\n<h2 id=\"weight-initialization-problems\" style=\"position:relative;\"><a href=\"#weight-initialization-problems\" aria-label=\"weight initialization problems permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Weight Initialization Problems</h2>\n<p>weight를 다음과 같이 초기화 해주게 되면 문제가 생깁니다.</p>\n<p><strong>① 작게 초기화하는 경우</strong></p>\n<ol>\n<li><strong>0.000..</strong> 이되도록 <strong>weight를 너무 0에 가깝게 초기화</strong> 하는 경우</li>\n<li><strong>많은 layer를 사용</strong>하면서 <strong>0에 가까운 값으로 weight를 초기화</strong> 하는 경우</li>\n</ol>\n<p><strong>② 크게 초기화하는 경우</strong></p>\n<p>위와 같은 경우에 왜 weight initialization problem이 생기는지 알아보겠습니다.</p>\n<hr>\n<p><strong>① 작게 초기화하는 경우</strong></p>\n<p>    작게 초기화 하는 경우, 우리는 다음과 같은 code로 weight를 초기화했다고 생각할 수 있습니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># Standard Gaussian Distribution which has standard deviation = 0.01</span>\nW <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>randn<span class=\"token punctuation\">(</span>fan_in<span class=\"token punctuation\">,</span>fan_out<span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token number\">0.01</span></code></pre></div>\n<p>    weight가 <strong>0.000..</strong> 이되도록 <strong>weight를 너무 0에 가깝게 초기화</strong> 하는 경우 학습이 전혀 진행되지 않게 됩니다. 이유는 다음과 같습니다.</p>\n<p align=\"center\">\n   <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 674px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 63.66666666666666%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsTAAALEwEAmpwYAAABSklEQVQ4y41TXYvCMBDM//9Rvvkk+CCIKAhS8LzScq39jE2buZ3U9DRWvIVp02wymcxulbUWjKIocL3mMH2PYRjg58P3p1B+4el0QpZlqKrKkWutp0Vc4/GJXI05iziOUTeNIzK9QS9K67p2ah8jJA7J1bsTb7cb2rZ1B3BclqWQ2yfiOVIVJgiqIhlVdl2Hy+WCXOxoZK6RW3BuTu1IOH7BshAe8v2oMIoi5Hk+bWLOGPMihFCObMZcqmSBGFRFtT44Zu6xcH9X5lMS1eGAbLeDPh5heD0uDrz1CqmcoFJ2RJIkroC0YiQUomixwM92i2y9RrtcYrIiwHi+nuzgm0QeI6F4VK5W6ESl3mxg93svabbXvB2+OLON3Yr8Wk5zG+6b3oHKvKcvRfGEX+cz0jRFKwVwuPs0h5DsuW3ug2/ptaIo//3PvmvsX8Tr/YjF2XMBAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"assets 2021 08 21 2\" title=\"assets 2021 08 21 2\" src=\"/static/52f34393bf55cfabad911e4764548c5a/fdaf8/2.png\" srcset=\"/static/52f34393bf55cfabad911e4764548c5a/5a46d/2.png 300w,\n/static/52f34393bf55cfabad911e4764548c5a/0a47e/2.png 600w,\n/static/52f34393bf55cfabad911e4764548c5a/fdaf8/2.png 674w\" sizes=\"(max-width: 674px) 100vw, 674px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span>\n</p>\n<p>    <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mrow><mi>ϑ</mi><mi>g</mi></mrow><mrow><mi>ϑ</mi><mi>x</mi></mrow></mfrac><mo>=</mo><mi>w</mi><mo>=</mo><mn>0.00..</mn></mrow><annotation encoding=\"application/x-tex\">{\\vartheta g \\over \\vartheta x} =w= 0.00..</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.277216em;vertical-align:-0.345em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9322159999999999em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">ϑ</span><span class=\"mord mathdefault mtight\">x</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.446108em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">ϑ</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">g</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span><span class=\"mord\">.</span><span class=\"mord\">0</span><span class=\"mord\">0</span><span class=\"mord\">.</span><span class=\"mord\">.</span></span></span></span>이기 때문에 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mrow><mi>ϑ</mi><mi>f</mi></mrow><mrow><mi>ϑ</mi><mi>x</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mi>ϑ</mi><mi>f</mi></mrow><mrow><mi>ϑ</mi><mi>g</mi></mrow></mfrac><mo>∗</mo><mfrac><mrow><mi>ϑ</mi><mi>g</mi></mrow><mrow><mi>ϑ</mi><mi>x</mi></mrow></mfrac><mo>=</mo><mn>0</mn><mo>∗</mo><mn>1</mn><mo>=</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">{\\vartheta f \\over \\vartheta x} = {\\vartheta f \\over \\vartheta g} * {\\vartheta g \\over \\vartheta x} = 0*1 = 0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.277216em;vertical-align:-0.345em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9322159999999999em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">ϑ</span><span class=\"mord mathdefault mtight\">x</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.446108em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">ϑ</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10764em;\">f</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.4133239999999998em;vertical-align:-0.481108em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9322159999999999em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">ϑ</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">g</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.446108em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">ϑ</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10764em;\">f</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.481108em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.277216em;vertical-align:-0.345em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9322159999999999em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">ϑ</span><span class=\"mord mathdefault mtight\">x</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.446108em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">ϑ</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">g</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span></span></span></span>이 됩니다. 이에 <strong>저 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">x</span></span></span></span>와 연결되어 있는 모든 이전 node들의 gradient는 0이 되므로 gradient vanishing 현상</strong>이 생기게 됩니다. 이에 학습이 되지 않는 상황이 생기게 되므로 weight를 0으로 초기화하면 학습이 진행되지 않습니다.</p>\n<p>    이제, <strong>많은 layer를 사용</strong>하면서 <strong>0에 가까운 값으로 weight를 초기화</strong> 하는 경우를 살펴보겠습니다.</p>\n<p>    activation function으로 tanh를 사용해서 학습을 진행하는 경우, 레이어를 통과하면 통과할 수록 모든 activation map의 값들이 0에 가까워지게 됩니다. 0에 가까운 weight들이 계속 곱해지면서 activation들이 0에 가까워지게 되고 tanh를 통과하면서 0으로 수렴하게 됩니다. 다시 이 값들이 0에 가까운 weight와 곱해지게 되면서 레이어가 깊어질 수록 모든 값들이 0으로 수렴되게 됩니다.</p>\n<p>   위와 같은 현상이 진행된다면 back propagation step에서 gradient vanishing현상이 일어나게 됩니다.</p>\n<p align=\"center\">\n   <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 674px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 63.66666666666666%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsTAAALEwEAmpwYAAABRElEQVQ4y41TTXOCMBDl//8bbx7bs87YjgfPYEVHRCmR78DrvmhSRGjdYSdLNnn79iXxIFaXJdLAx2GzQRmGaPMcHRNdJ5+J3PifeWbZdouv2QzRagW1XEK9vaNsWwNowboXwW+Aux2i+Rzf6zWqzw/oxQJaprPrFS2BezYEHoJ7rmJdA1V1c/mvZCyKAqXIwVgpJeDdA/AYqOcSPScrgmmtpU6N/X6P5HJBLnO56Mu5Mba/Lfc0st5nGAQBkiRxm5hrmuZJX7o3JTJZXkVDGlmRrTXGzLHY86HcwVSaIo5j1FJZ68awG5pdyxydTFPZF0URsiwzUjhA3/cN4Pl8xvF4dIyGLdHIzMrBkUDWHSBbYEUuGmtlTA57OKMtF+YEs4dNU86CUx04wFCe3OkUO33+8iHY47W5Bwe5a2mqXn6zUxf7B8K6/QgWdVRIAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"assets 2021 08 21 3\" title=\"assets 2021 08 21 3\" src=\"/static/3c725773a59fb0f28d97f5a7c37d1505/fdaf8/3.png\" srcset=\"/static/3c725773a59fb0f28d97f5a7c37d1505/5a46d/3.png 300w,\n/static/3c725773a59fb0f28d97f5a7c37d1505/0a47e/3.png 600w,\n/static/3c725773a59fb0f28d97f5a7c37d1505/fdaf8/3.png 674w\" sizes=\"(max-width: 674px) 100vw, 674px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span>\n</p>\n<p>forward pass를 했을 때, 들어온 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">x</span></span></span></span>값이 0이 된다면 backpropagation을 진행 할 때, upstream gradient와 local gradient를 곱할 경우 0이 됩니다. 이 과정은 아래의 수식과 같습니다</p>\n<span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mrow><mi>ϑ</mi><mi>f</mi></mrow><mrow><mi>ϑ</mi><mi>w</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mi>ϑ</mi><mi>f</mi></mrow><mrow><mi>ϑ</mi><mi>g</mi></mrow></mfrac><mo>∗</mo><mfrac><mrow><mi>ϑ</mi><mi>g</mi></mrow><mrow><mi>ϑ</mi><mi>w</mi></mrow></mfrac><mo>=</mo><mn>1</mn><mo>∗</mo><mn>0</mn><mo>=</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">{\\vartheta f \\over \\vartheta w} = {\\vartheta f \\over \\vartheta g} * {\\vartheta g \\over \\vartheta w} = 1*0 = 0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:2.0574399999999997em;vertical-align:-0.686em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3714399999999998em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">ϑ</span><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">ϑ</span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.25188em;vertical-align:-0.8804400000000001em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3714399999999998em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">ϑ</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">ϑ</span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8804400000000001em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.0574399999999997em;vertical-align:-0.686em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3714399999999998em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">ϑ</span><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">ϑ</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span></span></span></span></span>\n<p>    위의 수식에서 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mrow><mi>ϑ</mi><mi>f</mi></mrow><mrow><mi>ϑ</mi><mi>g</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">{\\vartheta f \\over \\vartheta g}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.4133239999999998em;vertical-align:-0.481108em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9322159999999999em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">ϑ</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">g</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.446108em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">ϑ</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10764em;\">f</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.481108em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span> 은 upstream gradient이며 local gradient는 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mrow><mi>ϑ</mi><mi>g</mi></mrow><mrow><mi>ϑ</mi><mi>w</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">{\\vartheta g \\over \\vartheta w}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.277216em;vertical-align:-0.345em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9322159999999999em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">ϑ</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02691em;\">w</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.446108em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">ϑ</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">g</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span> 입니다. 이것은 하나의 layer만 보고 설명한 것인데 network를 전체로 설명하자면 다음과 같습니다.</p>\n<p>    우리는 학습을 진행하기 위해 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mrow><mi>ϑ</mi><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi></mrow><mrow><mi>ϑ</mi><mi>w</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">{\\vartheta loss \\over \\vartheta w}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.2251079999999999em;vertical-align:-0.345em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8801079999999999em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">ϑ</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02691em;\">w</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">ϑ</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathdefault mtight\">o</span><span class=\"mord mathdefault mtight\">s</span><span class=\"mord mathdefault mtight\">s</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span> 를 구해야합니다. 이 값은 <strong>chain rule</strong>을 통해 구해 나가야하며 아래의 연산이 진행됩니다.</p>\n<span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mrow><mi>ϑ</mi><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi></mrow><mrow><mi>ϑ</mi><mi>w</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mi>ϑ</mi><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi></mrow><mrow><mi>ϑ</mi><mi>f</mi></mrow></mfrac><mo>∗</mo><mfrac><mrow><mi>ϑ</mi><mi>f</mi></mrow><mrow><mi>ϑ</mi><mi>g</mi></mrow></mfrac><mo>∗</mo><mfrac><mrow><mi>ϑ</mi><mi>g</mi></mrow><mrow><mi>ϑ</mi><mi>w</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">{\\vartheta loss \\over \\vartheta w} = {\\vartheta loss \\over \\vartheta f} * {\\vartheta f \\over \\vartheta g} * {\\vartheta g \\over \\vartheta w}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:2.05744em;vertical-align:-0.686em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.37144em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">ϑ</span><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">ϑ</span><span class=\"mord mathdefault\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathdefault\">o</span><span class=\"mord mathdefault\">s</span><span class=\"mord mathdefault\">s</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.25188em;vertical-align:-0.8804400000000001em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.37144em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">ϑ</span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">ϑ</span><span class=\"mord mathdefault\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathdefault\">o</span><span class=\"mord mathdefault\">s</span><span class=\"mord mathdefault\">s</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8804400000000001em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.25188em;vertical-align:-0.8804400000000001em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3714399999999998em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">ϑ</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">ϑ</span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8804400000000001em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.0574399999999997em;vertical-align:-0.686em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3714399999999998em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">ϑ</span><span class=\"mord mathdefault\" style=\"margin-right:0.02691em;\">w</span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">ϑ</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.686em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></span>\n<p>    위의 연산을 하기 위해서 upstream gradient와 local gradient(=<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">x</span></span></span></span>)를 곱해야하는데 local gradient인 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mrow><mi>ϑ</mi><mi>g</mi></mrow><mrow><mi>ϑ</mi><mi>w</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">{\\vartheta g \\over \\vartheta w}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.277216em;vertical-align:-0.345em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9322159999999999em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">ϑ</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02691em;\">w</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.446108em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">ϑ</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">g</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span>가 0이 되기 때문에 update가 일어나지 않게 되는 것입니다. 이를 통해 알 수 있듯이, <strong>activation의 값의 분포를 보고 학습이 잘될 수 있는지 될 수 없는지 알 수 있습니다</strong>. <strong>activation 값 중 0이 많으면 local gradient가 0이되어 학습에 악영향</strong>을 미치니까요😉</p>\n<p>② 크게 초기화하는 경우</p>\n<p>    다음은 크게 초기화하는 경우를 살펴보도록 하겠습니다. 작게 초기화한 경우, 가우시안 표준정규분포의 표준편차를 1로 두었지만 지금은 1로 선언합니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># Standard Gaussian Distribution which has standard deviation = 1.0</span>\nW <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>randn<span class=\"token punctuation\">(</span>fan_in<span class=\"token punctuation\">,</span>fan_out<span class=\"token punctuation\">)</span> <span class=\"token operator\">*</span> <span class=\"token number\">1.0</span></code></pre></div>\n<p>    이 때, <strong>tanh</strong> activation function을 사용하게 되면 layer를 통과했을 때, activation이 -1과 1로 치중되게 됩니다. 그 이유는 아래와 같습니다.</p>\n<p>    표준 편차가 큰 값으로 난수를 생성하여 weight를 초기화해주었습니다. 이후 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">x</span></span></span></span>와 행렬곱을 진행하게 되면 극단적으로 작거나 큰 값을 가지게 됩니다. 이 값들이 tanh를 지나게 된다면 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">x</span></span></span></span>축의 왼쪽과 오른쪽에 위치해서 tanh와 mapping되기 때문에 -1 이나 1값을 가지게 됩니다. 아래의 그림은 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>y</mi><mo>=</mo><mi>t</mi><mi>a</mi><mi>n</mi><mi>h</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">y = tanh(x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">t</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\">n</span><span class=\"mord mathdefault\">h</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span></span></span></span>의 그래프 입니다.</p>\n<p align=\"center\">\n   <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 1200px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 50.66666666666667%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAABR0lEQVQoz3VSy27EIAzk/z+wvbSHXlZt0jwhEAisd8aKV2nVIlmAGQ/jh9v3XY7jkFKKWs5Zrr5aqyzLIt57qafvqE1SCBKGQULfSfjuJc6zhHEQR0BrTQO5G5H57ve7bNumxkXSNI2ygSSDlBjF4e3A7qjInDRTyjPJSRwQuMUoFdjQfUkGeTmqElxjyeUYRBVmzx9xJhlXQgn8PMmOFBveTKnhrrGO9bGUaKzVuq56pjKS9bebfL6/SYRKwxFDrN35NqOObhxHvTDYnDQFpiR+muTj9UUm7BF3w1EISS024a3ruv9T5srBS0aqMSYl42IZfpfmR8rXpmiXWVykmTACEUZgONO3Kfirec+m6IhYh6EiIbUA6QUk7fzZamcqjNimwHzkciuCt77XcYiYr4i67PiJSsupnnXWwT6VkYjDT0U2t+Z7AMbzDHcWuFpwAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"assets 2021 08 21 4\" title=\"assets 2021 08 21 4\" src=\"/static/ba592191f9bc8ab4bdaf0de5e3f9cf44/c1b63/4.png\" srcset=\"/static/ba592191f9bc8ab4bdaf0de5e3f9cf44/5a46d/4.png 300w,\n/static/ba592191f9bc8ab4bdaf0de5e3f9cf44/0a47e/4.png 600w,\n/static/ba592191f9bc8ab4bdaf0de5e3f9cf44/c1b63/4.png 1200w,\n/static/ba592191f9bc8ab4bdaf0de5e3f9cf44/07e9f/4.png 1301w\" sizes=\"(max-width: 1200px) 100vw, 1200px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span>\n</p>\n<h2 id=\"weight-initialization-methods\" style=\"position:relative;\"><a href=\"#weight-initialization-methods\" aria-label=\"weight initialization methods permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Weight Initialization Methods</h2>\n<p>    weight를 초기화 하는 2가지 방법을 알아보도록 하겠습니다. 하나는 Xavier initialization이고 다른 하나는 He initialization 입니다. 먼저 Xavier initialization 부터 알아보도록 하겠습니다.</p>\n<p>① Xavier initialization</p>\n<p>    Xavier Initialization 은 uniform distribution 혹은 normal distribution으로 weight를 초기화할 때 다른 방법으로 초기화하게 되며 uniform distribution에서는 다음과 같은 범위를 사용합니다.</p>\n<p align=\"center\">\n   <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 375px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 19.333333333333332%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAp0lEQVQY032P2w6DIBBE/f9/FNQGamMJKHJRI9Nlta+SbCBnlslMg4dTSsGyLPDe813nOA7W1nW92K3t+868sdYixIQUA6x1/Lku520jFpFyZqaUxnmebJhvFklXSrFZSokDNJ9xhJs9ZufQdT1NB9G2MMbgNQzM3rQz9D2klGxS30IIKK3ZUAiJ6TtdCZ8q16Se6uS8cbLaphAPIZBxoGaRU9cw/8o/lPQ0PqCnfgkAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"assets 2021 08 21 5\" title=\"assets 2021 08 21 5\" src=\"/static/c533d514c5075b5e74faf47acbb4bca2/5ff7e/5.png\" srcset=\"/static/c533d514c5075b5e74faf47acbb4bca2/5a46d/5.png 300w,\n/static/c533d514c5075b5e74faf47acbb4bca2/5ff7e/5.png 375w\" sizes=\"(max-width: 375px) 100vw, 375px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span>\n</p>\n<p>    하지만, 정규 분포로 초기화할 경우 평균이 0이고 표준 편차가 아래와 같은 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>σ</mi></mrow><annotation encoding=\"application/x-tex\">\\sigma</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">σ</span></span></span></span>를 가지도록 초기화 합니다.</p>\n<p align=\"center\">\n   <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 156px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 48.07692307692307%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAABU0lEQVQoz5VT226CQBDl/3+mD9X2rUlr7M1EeyFttIFwFRRFkOXOcrq7KQpEHnqSyczOMmdnzi4SeqjruuP/A14jDW1wkCiCpmkwDEOYruuwLAumaYq4ydm2faqRGoK+cZiGib0fgBCCiJFz7203LHc45Zr8iXBotDLPxcl9vL1OIS+VwalEhzGJsNv7yNIUYRiKjSJPGaGDmlLkjLwoClGkayocdwtKK5HjVlVVV0N5McOH/IUg8GGtHWwcB7OXZxzjBK67YVrpQktFUaD/6WlZNtNPg6qq2Hlel5CyLtpIAg9X12MUJcXnfAb5e4Usy1GWBX5WCsLDHpOHCfyAsOmOSLLsTNh+JtyoWFOMxyPkbBJ3beJ9Mcfd/RSEdRwdCdIkYcRLPE6fcHszgrvzux22b5atwMOYxCLuCn/piV24lPZN1a2vuDsf1puEydT/Cbj/BXmtBLd3xKeZAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"assets 2021 08 21 6\" title=\"assets 2021 08 21 6\" src=\"/static/f05a4baa06c2e6cae4b96b1a9962b27c/680fe/6.png\" srcset=\"/static/f05a4baa06c2e6cae4b96b1a9962b27c/680fe/6.png 156w\" sizes=\"(max-width: 156px) 100vw, 156px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span>\n</p>\n<p>    따라서 해당 weight는 아래와 같은 정규 분포를 따르게 됩니다.</p>\n<span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi><mo stretchy=\"false\">(</mo><mn>0</mn><mo separator=\"true\">,</mo><mfrac><mn>2</mn><mrow><msub><mi>n</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo>+</mo><msub><mi>n</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub></mrow></mfrac><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\"> N(0,{2\\over n_{in}+n_{out}})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:2.1574400000000002em;vertical-align:-0.8360000000000001em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">N</span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.32144em;\"><span style=\"top:-2.3139999999999996em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\">n</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mord mathdefault mtight\">n</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">n</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">o</span><span class=\"mord mathdefault mtight\">u</span><span class=\"mord mathdefault mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\">2</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8360000000000001em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span><span class=\"mclose\">)</span></span></span></span></span>\n<p>   코드로는 아래와 같이 작성해주면 됩니다.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># xavier initialization</span>\nW <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>randn<span class=\"token punctuation\">(</span>fan_in<span class=\"token punctuation\">,</span> fan_out<span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> np<span class=\"token punctuation\">.</span>sqrt<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>fan_in<span class=\"token operator\">+</span>fan_out<span class=\"token punctuation\">)</span><span class=\"token operator\">/</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>    위의 식을 보게되면 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi><mo stretchy=\"false\">(</mo><mn>0</mn><mo separator=\"true\">,</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">N(0,1)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">N</span><span class=\"mopen\">(</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">1</span><span class=\"mclose\">)</span></span></span></span>인 표준 정규 분포에서 sampling한 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>W</mi></mrow><annotation encoding=\"application/x-tex\">W</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span></span></span></span>를 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msqrt><mrow><mn>2</mn><mi mathvariant=\"normal\">/</mi><mo stretchy=\"false\">(</mo><mi>i</mi><mi>n</mi><mo>+</mo><mi>o</mi><mi>u</mi><mi>t</mi><mo stretchy=\"false\">)</mo></mrow></msqrt></mrow><annotation encoding=\"application/x-tex\">\\sqrt{2/(in+out)}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.24em;vertical-align:-0.30499999999999994em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.935em;\"><span class=\"svg-align\" style=\"top:-3.2em;\"><span class=\"pstrut\" style=\"height:3.2em;\"></span><span class=\"mord\" style=\"padding-left:1em;\"><span class=\"mord\">2</span><span class=\"mord\">/</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">i</span><span class=\"mord mathdefault\">n</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathdefault\">o</span><span class=\"mord mathdefault\">u</span><span class=\"mord mathdefault\">t</span><span class=\"mclose\">)</span></span></span><span style=\"top:-2.8950000000000005em;\"><span class=\"pstrut\" style=\"height:3.2em;\"></span><span class=\"hide-tail\" style=\"min-width:1.02em;height:1.28em;\"><svg width='400em' height='1.28em' viewBox='0 0 400000 1296' preserveAspectRatio='xMinYMin slice'><path d='M263,681c0.7,0,18,39.7,52,119\nc34,79.3,68.167,158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120\nc340,-704.7,510.7,-1060.3,512,-1067\nl0 -0\nc4.7,-7.3,11,-11,19,-11\nH40000v40H1012.3\ns-271.3,567,-271.3,567c-38.7,80.7,-84,175,-136,283c-52,108,-89.167,185.3,-111.5,232\nc-22.3,46.7,-33.8,70.3,-34.5,71c-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1\ns-109,-253,-109,-253c-72.7,-168,-109.3,-252,-110,-252c-10.7,8,-22,16.7,-34,26\nc-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26s76,-59,76,-59s76,-60,76,-60z\nM1001 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30499999999999994em;\"><span></span></span></span></span></span></span></span></span>으로 나누는 것을 볼 수 있습니다. 그 이유는 1의 표준 편차를 가진 분포를 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msqrt><mfrac><mn>2</mn><mrow><msub><mi>n</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo>+</mo><msub><mi>n</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub></mrow></mfrac></msqrt></mrow><annotation encoding=\"application/x-tex\">\\sqrt {2 \\over n_{in}+n_{out}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.8400000000000003em;vertical-align:-0.654996em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.1850040000000002em;\"><span class=\"svg-align\" style=\"top:-3.8em;\"><span class=\"pstrut\" style=\"height:3.8em;\"></span><span class=\"mord\" style=\"padding-left:1em;\"><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">n</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3280857142857143em;\"><span style=\"top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mord mathdefault mtight\">n</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">n</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29634285714285713em;\"><span style=\"top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">o</span><span class=\"mord mathdefault mtight\">u</span><span class=\"mord mathdefault mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.44509999999999994em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span><span style=\"top:-3.1450039999999997em;\"><span class=\"pstrut\" style=\"height:3.8em;\"></span><span class=\"hide-tail\" style=\"min-width:1.02em;height:1.8800000000000001em;\"><svg width='400em' height='1.8800000000000001em' viewBox='0 0 400000 1944' preserveAspectRatio='xMinYMin slice'><path d='M983 90\nl0 -0\nc4,-6.7,10,-10,18,-10 H400000v40\nH1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7\ns-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744\nc-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30\nc26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722\nc56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5\nc53.7,-170.3,84.5,-266.8,92.5,-289.5z\nM1001 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.654996em;\"><span></span></span></span></span></span></span></span></span>의 표준편차를 갖는 분포로 바꾸기 위해서는 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msqrt><mfrac><mn>2</mn><mrow><msub><mi>n</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo>+</mo><msub><mi>n</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub></mrow></mfrac></msqrt></mrow><annotation encoding=\"application/x-tex\">\\sqrt {2 \\over n_{in}+n_{out}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.8400000000000003em;vertical-align:-0.654996em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.1850040000000002em;\"><span class=\"svg-align\" style=\"top:-3.8em;\"><span class=\"pstrut\" style=\"height:3.8em;\"></span><span class=\"mord\" style=\"padding-left:1em;\"><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">n</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3280857142857143em;\"><span style=\"top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mord mathdefault mtight\">n</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">n</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29634285714285713em;\"><span style=\"top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">o</span><span class=\"mord mathdefault mtight\">u</span><span class=\"mord mathdefault mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.44509999999999994em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span><span style=\"top:-3.1450039999999997em;\"><span class=\"pstrut\" style=\"height:3.8em;\"></span><span class=\"hide-tail\" style=\"min-width:1.02em;height:1.8800000000000001em;\"><svg width='400em' height='1.8800000000000001em' viewBox='0 0 400000 1944' preserveAspectRatio='xMinYMin slice'><path d='M983 90\nl0 -0\nc4,-6.7,10,-10,18,-10 H400000v40\nH1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7\ns-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744\nc-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30\nc26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722\nc56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5\nc53.7,-170.3,84.5,-266.8,92.5,-289.5z\nM1001 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.654996em;\"><span></span></span></span></span></span></span></span></span>를 곱해주어야 하기 때문입니다.</p>\n<p>    Xavier initialization은 <strong>non-linear activation function</strong>인 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>t</mi><mi>a</mi><mi>n</mi><mi>h</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">tanh(x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">t</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\">n</span><span class=\"mord mathdefault\">h</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span></span></span></span>와 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>o</mi><mi>i</mi><mi>d</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">sigmoid(x)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">s</span><span class=\"mord mathdefault\">i</span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">g</span><span class=\"mord mathdefault\">m</span><span class=\"mord mathdefault\">o</span><span class=\"mord mathdefault\">i</span><span class=\"mord mathdefault\">d</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">x</span><span class=\"mclose\">)</span></span></span></span>에서 <strong>좋은 성능</strong>을 보이지만 ReLU와 사용할 때 성능이 좋지 않습니다. 이에 ReLU를 사용할 땐 <strong>He initialization을 사용</strong>합니다.</p>\n<p>② He initialization</p>\n<p>    He initialization은 <strong>xavier initialization과 유사</strong>합니다. 정규 분포와 균등 분포 두가지로 나뉘게 되는데 He initialization는 xavier와 다르게 이전 층의 뉴런 수만 반영하고 다음 층의 뉴런 수를 반영하지 않습니다.</p>\n<p>    weight를 uniform dstribution으로 초기화할 경우 아래와 같은 균등 분포 범위를 가지도록 합니다.</p>\n<p align=\"center\">\n   <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 311px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 23%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAyklEQVQY042QWw+CMAyF+f//zOgz4BUMOi/cZYNN2I7dEKIvxpM0Tdru6+k8vGWMmfMUWuu5LrsOdV1DCPE1xzl3daWUq3vmA/ZL9mEUxWgJPKnvB2RpCsbYvMRTLcdiuYJoO6TU9H0fYRhivdlgHQY4syuKPEdeFDgeY+fG7he8cfMWliQJcpoZHeoBnM6w5z2fyjnJqFlVFaqydI5uF4b9IcKWltwJYoF6GBAEPsFO2O52aB7NCMQfMkZDSuX+qSfQJCmlM2LzpBfJC4MDSvpFVwAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"assets 2021 08 21 7\" title=\"assets 2021 08 21 7\" src=\"/static/a158b94d2a7ed91cdefc9060c5ae2b7a/ffa0f/7.png\" srcset=\"/static/a158b94d2a7ed91cdefc9060c5ae2b7a/5a46d/7.png 300w,\n/static/a158b94d2a7ed91cdefc9060c5ae2b7a/ffa0f/7.png 311w\" sizes=\"(max-width: 311px) 100vw, 311px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span>\n</p>\n<p>    하지만, 정규 분포로 초기화할 경우 아래와 같은 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>σ</mi></mrow><annotation encoding=\"application/x-tex\">\\sigma</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">σ</span></span></span></span>를 사용합니다</p>\n<p align=\"center\">\n   <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 125px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 58.4%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsTAAALEwEAmpwYAAABWElEQVQoz41T226CQBD1/3+iDyYkfdG+NeqbTRu1tmnSpgokXoh4KVqQO+yyx90lmKpInWR2FuZwmD0zW8M/xuTCrufPcrVKMgHmLj6J4xhBEMD3fRnDMESWZRektaraCmAcBej1h9A0DZPpFLqmYqyqSJLkkrB4ELHMhW1XBrZuJPf66Au2Fx3lKD0yu6JRcaQZryqKcpLO4wNGk8VJvrTCjBJ4ngvKQYQQUEqPoNlsDscN4O1tDAZ9mMsNEq7p+UkkYfGXz7dXKEoDCUnx8T6EYa6wdxy8PPdgWRtYvw50XYdhzDEej3g0TqS6qNBzXfhhLPdpmsq431loNJsw11up2HK5AGHXR6ZUw2OT5ErRvK9DXTiIAwdK/Q6tdhvd7hPMlV1d4d+EiJTmUnTaLaw3Vv4+Y9j9mPjmnbZs7/bBzuc5BxJOzFh20y2pIGQok6Jw0cgyjLAD2C2mORSbceIAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"assets 2021 08 21 8\" title=\"assets 2021 08 21 8\" src=\"/static/5f2fa01ea22e68945c1f620a71e276bf/fac75/8.png\" srcset=\"/static/5f2fa01ea22e68945c1f620a71e276bf/fac75/8.png 125w\" sizes=\"(max-width: 125px) 100vw, 125px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span>\n</p>\n&nbsp; &nbsp; 따라서 아래와 같은 코드를 사용하면 He initialization을 적용할 수 있습니다.\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token comment\"># He initialization</span>\nW <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>randn<span class=\"token punctuation\">(</span>fan_in<span class=\"token punctuation\">,</span> fan_out<span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> np<span class=\"token punctuation\">.</span>sqrt<span class=\"token punctuation\">(</span>fan_in<span class=\"token operator\">/</span><span class=\"token number\">2</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># W = np.random.randn(fan_in, fan_out) * np.sqrt(2/fan_in)</span>\n<span class=\"token comment\"># In Pytorch...</span>\ntorch<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>init<span class=\"token punctuation\">.</span>kaiming_normal_<span class=\"token punctuation\">(</span>tensor<span class=\"token punctuation\">,</span> a<span class=\"token operator\">=</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> mode<span class=\"token operator\">=</span><span class=\"token string\">'fan_in'</span><span class=\"token punctuation\">,</span> nonlinearity<span class=\"token operator\">=</span><span class=\"token string\">'leaky_relu'</span><span class=\"token punctuation\">)</span></code></pre></div>\n<h2 id=\"more-details-about-xavier-initialization--he-initialization\" style=\"position:relative;\"><a href=\"#more-details-about-xavier-initialization--he-initialization\" aria-label=\"more details about xavier initialization  he initialization permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>More Details about Xavier initialization &#x26; He initialization</h2>\n<p>    <strong>Xavier initialization</strong>은 <strong>tanh나 sigmoid형태의 비선형 함수에서 잘 동작</strong>합니다. 쉽게 설명하면 <strong>sigmoid와 tanh의 saturation영역으로 activation value들이 들어가지 않도록 설정</strong>해주기 때문입니다. 즉, sigmoid와 tanh의 <strong>linear 영역에 activation value들이 들어가도록</strong> 하면서 <strong>saturation에 빠지지 않도록 activation value를 조정</strong>합니다. 하지만 hidden layer가 3개가 넘어가 <strong>4개가 된다면 학습이 제대로 진행이 되지 않습니다</strong>. 아래의 그림은 sigmoid activation function을 통과한 각각의 layer의 activation value의 분포를 나타낸 것입니다.</p>\n<p align=\"center\">\n   <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 767px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 36%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsTAAALEwEAmpwYAAABiUlEQVQoz2WQ7WvTUBSH81/70c/6QVBaGA6dg8GEtYpiYZ0My6QV53RCmWUkaWuxaTFNlrfm9SaPJ62Doefy457Dveft0RAry0qkau8fqf9Uydm+1jnlRndNU6okjtfkmcK1YT6D2QQmesVYB1M0NiQew9KCNMhQ9gq1ljsvyfOCLBNfqY20MAzxfY9e3+Vl5yetE4P26TWvz6559f6Sdvcz7c5HWm97vOl+4vywy7yzz7J/hPv1hGz4hfD3AmuxwLu5QYuiCHM85Vg+XfSf8n2wy/Bij9HVIVeDHX6cNRl9aDDqNdHPnzE4btB8fp/m43s0Hj3g4N0uU1lpblnYtl1PGOE4DkkUbiHc4ivuoCv+KhSGRcI3e8hp64jWw32e7Oyh6yaWFFytVmg11Hptx3XxgwBXxvbDAC/wCdcRgTSK02QTR0kseAJJtJlPDS67HQYHL7B/zVBVRVEUaPVQNdQ0TUmShECK5nnOZDLZrKDrOkvhY5omC5nCMHQ8z5PGHo4vTeJtzq39AVxOAm1nlQ1BAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"assets 2021 08 21 9\" title=\"assets 2021 08 21 9\" src=\"/static/1b60077b602ac4cb7c1bff51f9be97f9/6c2f2/9.png\" srcset=\"/static/1b60077b602ac4cb7c1bff51f9be97f9/5a46d/9.png 300w,\n/static/1b60077b602ac4cb7c1bff51f9be97f9/0a47e/9.png 600w,\n/static/1b60077b602ac4cb7c1bff51f9be97f9/6c2f2/9.png 767w\" sizes=\"(max-width: 767px) 100vw, 767px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span>\n</p>\n<p>    이런 현상이 일어나는 이유는 <strong>각 layer를 통과할 때마다 activation function을 통과한 acitivation value들의 분포가 linear한 영역에 있지 못하고 saturation영역에 들어가 분포가 흔들리기 때문</strong>입니다. 위의 각각의 그래프는 평균과 표준편차를 나타냅니다. 4개의 layer를 지나게 되면 sigmid activation을 통과한 activation value들의 ideal한 평균인 <strong>0.5에 현저히 못미치는 것</strong>을 볼 수 있습니다.</p>\n<p>    이에 각 layer의 activation function을 통과한 <strong>activation value들의 분포를 모두 똑같이(mean과 standard deviation을 동일하게) 만들어주기 위해</strong>서 <strong>“이전 layer의 input 갯수(<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi><mi>a</mi><msub><mi>n</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">fan_{in}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mord mathdefault\">a</span><span class=\"mord\"><span class=\"mord mathdefault\">n</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mord mathdefault mtight\">n</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>)와 다음 layer의 output 개수(<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi><mi>a</mi><msub><mi>n</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">fan_{out}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mord mathdefault\">a</span><span class=\"mord\"><span class=\"mord mathdefault\">n</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">o</span><span class=\"mord mathdefault mtight\">u</span><span class=\"mord mathdefault mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>)를 통해 weight를 초기화”</strong> 합니다. 이전 layer의 input개수를 통해서 설정하는 이유는 activation value들을 sigmoid나 tanh의 saturation 영역으로 보내지 않고 <strong>linear한 영역으로 가져가기 위함</strong>이고 <strong>output 개수를 통해 weight를 초기화하는 이유</strong>는 <strong>backpropagation</strong>과 관련이 있다고 합니다. 이렇게 해서 나온 initialization이 <strong>Xavier initialization</strong>입니다. Xavier initialization는 weight의 표준편차를 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msqrt><mfrac><mn>2</mn><mrow><mi>f</mi><mi>a</mi><msub><mi>n</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo>+</mo><mi>f</mi><mi>a</mi><msub><mi>n</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub></mrow></mfrac></msqrt></mrow><annotation encoding=\"application/x-tex\">\\sqrt{2\\over fan_{in}+fan_{out}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.8400000000000003em;vertical-align:-0.6729999999999999em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.1670000000000003em;\"><span class=\"svg-align\" style=\"top:-3.8em;\"><span class=\"pstrut\" style=\"height:3.8em;\"></span><span class=\"mord\" style=\"padding-left:1em;\"><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.845108em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10764em;\">f</span><span class=\"mord mathdefault mtight\">a</span><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">n</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3280857142857143em;\"><span style=\"top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mord mathdefault mtight\">n</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span><span class=\"mbin mtight\">+</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10764em;\">f</span><span class=\"mord mathdefault mtight\">a</span><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">n</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.29634285714285713em;\"><span style=\"top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">o</span><span class=\"mord mathdefault mtight\">u</span><span class=\"mord mathdefault mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.481108em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span><span style=\"top:-3.127em;\"><span class=\"pstrut\" style=\"height:3.8em;\"></span><span class=\"hide-tail\" style=\"min-width:1.02em;height:1.8800000000000001em;\"><svg width='400em' height='1.8800000000000001em' viewBox='0 0 400000 1944' preserveAspectRatio='xMinYMin slice'><path d='M983 90\nl0 -0\nc4,-6.7,10,-10,18,-10 H400000v40\nH1013.1s-83.4,268,-264.1,840c-180.7,572,-277,876.3,-289,913c-4.7,4.7,-12.7,7,-24,7\ns-12,0,-12,0c-1.3,-3.3,-3.7,-11.7,-7,-25c-35.3,-125.3,-106.7,-373.3,-214,-744\nc-10,12,-21,25,-33,39s-32,39,-32,39c-6,-5.3,-15,-14,-27,-26s25,-30,25,-30\nc26.7,-32.7,52,-63,76,-91s52,-60,52,-60s208,722,208,722\nc56,-175.3,126.3,-397.3,211,-666c84.7,-268.7,153.8,-488.2,207.5,-658.5\nc53.7,-170.3,84.5,-266.8,92.5,-289.5z\nM1001 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6729999999999999em;\"><span></span></span></span></span></span></span></span></span>이 되게 만드는데 이는 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo>∗</mo><mo>∗</mo><mi>f</mi><mi>a</mi><msub><mi>n</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">**fan_{in}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.46528em;vertical-align:0em;\"></span><span class=\"mord\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mord mathdefault\">a</span><span class=\"mord\"><span class=\"mord mathdefault\">n</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mord mathdefault mtight\">n</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>과 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>f</mi><mi>a</mi><msub><mi>n</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">fan_{out}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mord mathdefault\">a</span><span class=\"mord\"><span class=\"mord mathdefault\">n</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">o</span><span class=\"mord mathdefault mtight\">u</span><span class=\"mord mathdefault mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>의 조화평균**입니다.</p>\n<p>    하지만 Xavier initialization은 아까 설명했던 것 처럼 <strong>sigmoid나 tanh와 같은 비선형 함수의 선형부분에 activation value들을 mapping시켜주어 forward와 backprop이 잘되게 해준 것</strong>이라 <strong>ReLU에는 잘 작동을 하지 않습니다</strong>. 이에 <strong>He initialization</strong>을 사용해줍니다.</p>\n<p>    <strong>He intialization</strong>은 Xavier initialization의 표준편차에 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msqrt><mn>2</mn></msqrt></mrow><annotation encoding=\"application/x-tex\">\\sqrt{2}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.04em;vertical-align:-0.13278em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.90722em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\">2</span></span></span><span style=\"top:-2.86722em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.13278em;\"><span></span></span></span></span></span></span></span></span>를 곱해주어 <strong>weight의 분포를 좀 더 넓은 형태</strong>로 잡도록 도와줍니다. 왜냐하면 <strong>ReLU에서는 음의 영역에 있는 값들은 모두 activaion function을 지나게 되면 0이 되기 때문</strong>입니다. 이에 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msqrt><mn>2</mn></msqrt></mrow><annotation encoding=\"application/x-tex\">\\sqrt{2}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.04em;vertical-align:-0.13278em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.90722em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\">2</span></span></span><span style=\"top:-2.86722em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.13278em;\"><span></span></span></span></span></span></span></span></span>배 만큼 표준편차를 더 늘려주면서 <strong>layer를 통과할 때마다 양의 영역에 있는 activation 값들을 좀 더 펴주는 역할을 수행</strong>합니다.</p>\n<p>    좀 더 다르게 해석해 본다면 직관적으로 봤을 때, <strong>ReLU는 음의 영역에 있는 activation value들을 없애므로써 입력을 반토막 낸다</strong>고 볼 수 있습니다. 이에 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo>∗</mo><mo>∗</mo><mi>f</mi><mi>a</mi><msub><mi>n</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">**fan_{in}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.46528em;vertical-align:0em;\"></span><span class=\"mord\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10764em;\">f</span><span class=\"mord mathdefault\">a</span><span class=\"mord\"><span class=\"mord mathdefault\">n</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mord mathdefault mtight\">n</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>에 2를 나눠서 마치 실제 입력의 반만큼만 입력으로 반영**된다고 생각할 수 있습니다. 이에 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mrow><mi>f</mi><mi>a</mi><msub><mi>n</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub></mrow><mn>2</mn></mfrac></mrow><annotation encoding=\"application/x-tex\">fan_{in} \\over 2</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.277216em;vertical-align:-0.345em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9322159999999999em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.446108em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10764em;\">f</span><span class=\"mord mathdefault mtight\">a</span><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">n</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3280857142857143em;\"><span style=\"top:-2.357em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mord mathdefault mtight\">n</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span>를 해준 것입니다.</p>\n<p>    아래의 사진①은 He initialization 이 아닌 Xavier initialization을 사용했을 떄의 모습이며 사진②는 He initialization 을 사용했을 때의 activation value의 distribution입니다.</p>\n<p align=\"center\">\n&lt;사진①&gt;\n</p>\n<p align=\"center\">\n   <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 544px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 63%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsTAAALEwEAmpwYAAACbklEQVQ4y2WTz2sTQRTH8x/pxasXTx70IiiKJ/8BBQ8VBMEUFKEnT4V68OAhYDVUDWqg1B8HqcWUZpsfjSbZZGazv7fZH9lNNrv5OjvZJht9MOxnZ9585817b3JRFGEWx3AcB5ZlAbPZgmcZjjM+c38bZjqfWOKbWG7keSCSgj6hkCQKVTdBqARKCBTG0mAA0u/DMC10ewSUUmhSH52mAFHsIgiChWAycp7notnuIZhEfKHTlzEOlxxG85NlRYPth5yJ2MHQ1BMZ+P8KBr6Pdk+C64/5gkgVjIIJ5y7jYBzyjbKqw3KChaCmyIin4f+CnuvihEXoZURG45QJE5xMOSuajqE3P7TZbOGo3mYUw099z4xFOMIfka4KBktBfzy/JpU1UMPlfHB4jA/fBUYTuKcGZmGAKHBZsaKkKPMcev5S0E05uX4Uzaso/CbY2e9y3q8IePH+J2D1YMsiIkdHaBDETHgRYTZv7CjOR60+do/ogtcLvzhXqg3kt0qI/SGCtIArV251ySLCZlfCq70TzrU2xbWnZZ7HDpFxa2MXMUt89biBtc0yZtEUvn9WlDit8shDtdXDnedfsPmpgYO6iHN3t/Hk9SFa4gDn773B5sc6608DF+4XUWkbEDttXM+/hWV7iKZhpsoswqQlmh2Ky492cPFBEcVvAm5vlHHp4Tts71Vx49lnXMmX8LXSwtX1EtZe/oAg1HDzcQGFvRqStltpm+THcVwWuo8wDKGqGoa2DZsNjbVKsua4Hmtslc+pxinvQXdoYeiM+L4VwbM3mM7CMAxoqgpZHsA0TT4cJqQoCgxdh8q+NnvTWctq/AXe5MXM+PCz2QAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"assets 2021 08 21 10\" title=\"assets 2021 08 21 10\" src=\"/static/22494eb799f2e44eca3e81794f6efe54/b3e51/10.png\" srcset=\"/static/22494eb799f2e44eca3e81794f6efe54/5a46d/10.png 300w,\n/static/22494eb799f2e44eca3e81794f6efe54/b3e51/10.png 544w\" sizes=\"(max-width: 544px) 100vw, 544px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span>\n</p>\n<p align=\"center\">\n&lt;사진②&gt;\n</p>\n<p align=\"center\">\n   <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 548px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 62.66666666666667%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsTAAALEwEAmpwYAAACMElEQVQ4y5WTS2/TQBDH81U5cOJAkUAVEuICCIkDJ4RakBCgHijwCaBEPJJCSEtLL4GGhiTEju1dO3Fsr9ev/Jn1qwk35rJ/j8a/ncdOI45jRFEEzjk0TUOWZbVO03TNzxjL9XK5rLWKUaZ8yhpB4OP0bAjdsGBzhtFkCsPiYJYFbWpCMxgs04ROeqyb4MzKY8ea0gyu69YwdTZCIdD//QeBTHLniAJFqTX60QvjXE9NhnlQaJ0ucTyZaz8I8uxrYOB7+PFrCE/IGlhp9ePcV3qZA51FWPhJczcogL6/DoykxNlIWwP6IiozpJICWWfoeOdA+18gwcoM/TzDCvLfwECg6GBhDRmGeQ/XS47qHrr+CrAqmfx1yY6FeGYg9WxkiVRAgdPBGIsyk+HEqIGTqYUZNV+VpCDVIFTmjk8xsYBrjJAsWAGMCShoSgpYvSc1iCgupsy4jSQp/Jz0vMyWmzrMqQ6EJiKXIVstORQB+sMJNp9+wa3dI7S+D3D1yWdsPuugedjHjZ0ubr/8hv2TAS5ttXB95wDN9iEu3H+Diw/3cXTSI0yGrBpK1eSbz1vY2P6Ad90e7u52sPHoI95+/Yk7Lzq4vPUezYNT3HvVxZXHn7DXPsaD121c295D97iXZ5ZlK0Api7emLJYh9SLEkvpj01Yk0qfoCI7NEQkPKX1HUlBk0Qpk5Vmt3vnaFLcoW3geTFo9x3HgzGa0XovcN6c1Y4wjph6ryDRbru2xOv8C9pvTf5MgYB0AAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"assets 2021 08 21 11\" title=\"assets 2021 08 21 11\" src=\"/static/4716bb99ed7199227455e149e7745aef/a58fe/11.png\" srcset=\"/static/4716bb99ed7199227455e149e7745aef/5a46d/11.png 300w,\n/static/4716bb99ed7199227455e149e7745aef/a58fe/11.png 548w\" sizes=\"(max-width: 548px) 100vw, 548px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span>\n</p>\n<p>    해당 session과 관련된 내용(Xavier initialization 설명)은 아래 링크를 통해 들어가시면 보실 수 있습니다. 구글링을 하며 공부하던 중 감명깊게 읽은 블로그입니다👍</p>\n<p>link: <a href=\"https://nittaku.tistory.com/269\">https://nittaku.tistory.com/269</a></p>\n<h2 id=\"code\" style=\"position:relative;\"><a href=\"#code\" aria-label=\"code permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Code</h2>\n<p>    Xavier, He initialization을 배우고 나서 GAN의 code에 직접 initialization을 적용해보았습니다. 두 개의 model을 설계하였는데 하나는 initialization을 그냥 random하게 준 것이고 다른 하나는 He initialization과 Xavier initialization을 통해 초기화 해주었습니다. <strong>Leaky ReLU를 사용한 부분은 He initilization</strong>을, <strong>tanh나 sigmoid를 사용한 부분은 Xavier initialization을</strong> 사용해주었습니다. 결과는 아래와 같습니다.</p>\n<p align=\"center\">\n   &lt; Generator Loss &gt;\n</p>\n<p align=\"center\">\n   <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 779px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 67.66666666666666%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAA7DAAAOwwHHb6hkAAABSklEQVQ4y61U2XLDIAz0//9oMlNf3Jdhi+QSEztuX8qMsoDWGyEhBmstvPdwzjH2c2MMHo8Hns8n4zRNCCGwv3EIjbEYq09KiSFZCWwBuQCllJfRaNiPtpdz3rGu85Yg1hVCCAxRTSjRsiCR6IOG27bxvGGz5uuRBs1ZMAeDLZPQIXAW7O2OQ+kYkp6B5FBwPXI7Vr9/OXLHSSlhCHJ8RXiOggh3ETZfzzkijO6tKOd/b3nr7TbCWAVz0D85zJf83BXn7COLMdK1UYCXdaNcqtzjX1U+BEM9rqcI8/9EqF3AOC81CXm/pB8E8+ke/iq4moCveYUVI0dZCi6dwoVg3K11yDsHuyD90LBGQ4kFzkgYLXm9o7o1Vzlt7p3Zq6y1RqhNbi01vGchIVZufEJqfupTrRW0UvUBEKAHZVlm5qxLDaKuVX0Y6HH4BhnGTWfIPiUtAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"assets 2021 08 21 12\" title=\"assets 2021 08 21 12\" src=\"/static/9b05261c4c304cbb3274ab88a139f0ec/96e92/12.png\" srcset=\"/static/9b05261c4c304cbb3274ab88a139f0ec/5a46d/12.png 300w,\n/static/9b05261c4c304cbb3274ab88a139f0ec/0a47e/12.png 600w,\n/static/9b05261c4c304cbb3274ab88a139f0ec/96e92/12.png 779w\" sizes=\"(max-width: 779px) 100vw, 779px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span>\n</p>\n<p>    위의 그래프는 initialization 해준 그래프(<span style=\"color:orange\">주황색</span>)와 initilization을 해주지 않은 그래프(<span style=\"color:blue\">파란색</span>) 입니다. 이것은 Generator loss로 initialization을 해준 그래프가 처음엔 <strong>loss가 엄청나게 뛰다가 빠르게 낮아지면서 initialization을 해주지 않은 그래프보다 loss가 작아진 것</strong>을 볼 수 있습니다. <strong>급격하게 loss가 올라가 있는 부분</strong>은 discriminator의 학습이 압도적으로 잘되어 discriminator가 <strong>generator가 만든 image를 보고 fake image라고 잘 판단</strong>하였기 때문입니다. discriminator쪽에도 initialization을 적용해주었기 때문에 초반 epoch 에서 initialization을 적용한 generator의 loss가 initialization을 적용하지 않은 generator의 loss보다 엄청나게 큰 것 볼 수 있습니다. 또한, 초기화를 해준 generator가 안해준 generator 보다 학습이 급속도로 잘되는 것을 볼 수 있습니다.</p>\n<p align=\"center\">\n   < Discriminator Loss >\n</p>\n<p align=\"center\">\n   <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 784px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 67%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAA7DAAAOwwHHb6hkAAABa0lEQVQ4y6VT207DMAzt/38iL5NAIDrU9ZK7neRgp7Tr0IZARHVPYjvxvYsxIjOjAijJAfYMhEloRgkLajQAe+ToRC4YjPBsQz0XCgB5LEOPyzCgIyKwPKgrLz365ydMi8FsPWZPMJFhlQLBpwwne0+58VxIcN4jhACi1N7prLXgnFE5on89YbQRQS4EYpSSkVVWy4pFkfdzkTNxRhT9JJgSoSv5y9o84PR+wbokAbXKt5IuvXyD3+QtQnmrC+LyRbx668+glJqCCjYP7uGmc+Q3byV9HTNhNA4v54swr1ZV4S+o1HKoFf6YDIZx2kP614NaIeM8xmncFR6F+hPuIedcwCS9SJq/tSC13tK9otzTaUXRPmJtVmmHo9UjKU/DOeLjooiHxQ5imrB1wG89POK1bWT0kp0k7CRNys2DI6lVVdwmajsf5ds+Sdt1+gshNoFzrqHOt5dUKK5jRViWpV3a0Biz66mO7lX2CU2G/pG63CbuAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"assets 2021 08 21 13\" title=\"assets 2021 08 21 13\" src=\"/static/a984d0293d9219e140d3810dbbda97d4/4971b/13.png\" srcset=\"/static/a984d0293d9219e140d3810dbbda97d4/5a46d/13.png 300w,\n/static/a984d0293d9219e140d3810dbbda97d4/0a47e/13.png 600w,\n/static/a984d0293d9219e140d3810dbbda97d4/4971b/13.png 784w\" sizes=\"(max-width: 784px) 100vw, 784px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span>\n</p>\n<p>    <strong>initialization을 적용한 그래프가 적용하지 않은 그래프보다 초반 epoch에서 loss가 더 낮은</strong> 것을 확인해 볼 수 있습니다. 이것은 <strong>initialization을 통해 discriminator의 가중치가 잘 설정되었기 때문</strong>입니다. 하지만 epoch가 점점 경과되면서 initialization이 적용된 discriminator의 loss가 <strong>25 epoch 이후로 더 높은 것을 확인</strong>할 수 있습니다. 이것은 initialization이 적용된 Generator의 학습이 잘 되었기 때문입니다. Initialization을 적용한 discriminator의 loss가 initialization을 적용하지 않은 discriminator보다 높으므로 <strong>initialization을 적용한 discriminator가 Generator를 더 잘 학습</strong>된 것을 알 수 있습니다.</p>\n<p align=\"center\">\n   &lt; Generator Accuracy &gt;\n</p>\n<p align=\"center\">\n   <span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 791px; \">\n      <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 67%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAA7DAAAOwwHHb6hkAAABf0lEQVQ4y5VTa2/jMAzL//+P923YoV3T2I6f8YMT1booggF3MyLIthSapJOl1opSCpiP43hGwSHr2jr23WN3FrvdsG83pP2OGi2OFFCfvSklXK5XGGOwxBjRWsMYA11y7x1tAL1EjLgB2QLJoEcDQUFLHk3m1d+lbjDCCsQ7ivuC9x4L0V+AAsYY2WlTlZddSLDxwBYKNslGo+p69bInwXrMD3ULpRKQowsoyo7kVm26ODYXlPpgzjE0z8MH8tEQS0WuXawTwBCC+idQSvvr4w/+2gKfCt+Wh+y7HkqQ+gRXVQr6yAzexUKak2H2FtY5PMYACasFTztUxSmzNkMl55wFUIqjYVuvSp3M3oH+ledcASk5iQ9HjritNzTxhYynxP/Jc66SW6tiakPJCVniXcac/yT1LJlDGXq/6y15Z0D551N/zbDKwpkVRvwbJ5PPXk1mP61fHhL1dvmE9eHV8G70ry+Fv14MXj/KlKLK5t/D4GGsc4+Xx/U5zzr7ufcNrPT9M1ywqoEAAAAASUVORK5CYII='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"assets 2021 08 21 14\" title=\"assets 2021 08 21 14\" src=\"/static/b66d9fb7702fe4ff829e873aebe22e93/cc8d6/14.png\" srcset=\"/static/b66d9fb7702fe4ff829e873aebe22e93/5a46d/14.png 300w,\n/static/b66d9fb7702fe4ff829e873aebe22e93/0a47e/14.png 600w,\n/static/b66d9fb7702fe4ff829e873aebe22e93/cc8d6/14.png 791w\" sizes=\"(max-width: 791px) 100vw, 791px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\">\n    </span>\n</p>\n&nbsp; &nbsp; 위의 그림은 epoch가 지남에 따라, 두 개의 model이 학습하고있는 Generator의 accuracy 변화를 보여주고 있습니다. Initialization을 사용한 model이 accuracy가 더 높은 것을 알 수 있습니다.\n<p>    따라서 이 실험을 통해 <strong>initialization을 사용</strong>하면 <strong>모델이 좀 더 빨리 학습될 뿐만 아니라 performance도 더 좋아진다는 것</strong>을 알 수 있었습니다.</p>\n<p>위의 실험 결과에 대한 코드는 아래의 링크를 통해 볼 수 있습니다😉</p>\n<p>link: <a href=\"https://github.com/gunu9441/AI/blob/main/8.GAN/Comparing_performance/1_GAN_MNIST_Origin_He%26Xavier.ipynb\">xavier과 he initialization을 적용한 model VS origin model</a></p>\n<h2 id=\"summary\" style=\"position:relative;\"><a href=\"#summary\" aria-label=\"summary permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Summary</h2>\n<ol>\n<li>Weight Intialization Problem은 <strong>weight가 너무 작거나 크게되면 문제가 발생</strong>합니다.</li>\n<li>각 레이어의 출력 분포를 확인하면 학습이 잘 되는지 확인할 수 있습니다. 만약 너무 극단적인 분포를 갖게 된다면(0으로 치중되거나 -1과 1로 퍼지는 현상) 학습이 잘 진행되지 않습니다. <strong>layer의 output 값들이 0으로 치중</strong>되는 경우, <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mrow><mi>ϑ</mi><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi></mrow><mrow><mi>ϑ</mi><mi>w</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mi>ϑ</mi><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi></mrow><mrow><mi>ϑ</mi><mi>f</mi></mrow></mfrac><mo>∗</mo><mfrac><mrow><mi>ϑ</mi><mi>f</mi></mrow><mrow><mi>ϑ</mi><mi>g</mi></mrow></mfrac><mo>∗</mo><mfrac><mrow><mi>ϑ</mi><mi>g</mi></mrow><mrow><mi>ϑ</mi><mi>w</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">{\\vartheta loss \\over \\vartheta w} = {\\vartheta loss \\over \\vartheta f} * {\\vartheta f \\over \\vartheta g} * {\\vartheta g \\over \\vartheta w}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.2251079999999999em;vertical-align:-0.345em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8801079999999999em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">ϑ</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02691em;\">w</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">ϑ</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathdefault mtight\">o</span><span class=\"mord mathdefault mtight\">s</span><span class=\"mord mathdefault mtight\">s</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.3612159999999998em;vertical-align:-0.481108em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8801079999999999em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">ϑ</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10764em;\">f</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">ϑ</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathdefault mtight\">o</span><span class=\"mord mathdefault mtight\">s</span><span class=\"mord mathdefault mtight\">s</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.481108em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.4133239999999998em;vertical-align:-0.481108em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9322159999999999em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">ϑ</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">g</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.446108em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">ϑ</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10764em;\">f</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.481108em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">∗</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.277216em;vertical-align:-0.345em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9322159999999999em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">ϑ</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02691em;\">w</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.446108em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">ϑ</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">g</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span>를 구할 때 local gradient인 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mrow><mi>ϑ</mi><mi>g</mi></mrow><mrow><mi>ϑ</mi><mi>w</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">{\\vartheta g \\over \\vartheta w}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.277216em;vertical-align:-0.345em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9322159999999999em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">ϑ</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02691em;\">w</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.446108em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">ϑ</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">g</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span>는 0이 됩니다(local gradient <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mrow><mi>ϑ</mi><mi>g</mi></mrow><mrow><mi>ϑ</mi><mi>w</mi></mrow></mfrac><mo>=</mo><mi>x</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding=\"application/x-tex\">{\\vartheta g \\over \\vartheta w} = x=0</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.277216em;vertical-align:-0.345em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9322159999999999em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">ϑ</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02691em;\">w</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.446108em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">ϑ</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">g</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">x</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span></span></span></span>).이에 되면 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mrow><mi>ϑ</mi><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi></mrow><mrow><mi>ϑ</mi><mi>w</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">{\\vartheta loss \\over \\vartheta w}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.2251079999999999em;vertical-align:-0.345em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8801079999999999em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">ϑ</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02691em;\">w</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">ϑ</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathdefault mtight\">o</span><span class=\"mord mathdefault mtight\">s</span><span class=\"mord mathdefault mtight\">s</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span> 가 0 이되어 학습이 되지 않습니다.\n<strong>Layer의 output 값들이 -1 이나 1로 치중되는 경우</strong>, activation function의 saturation area의 gradient(around 0)가 chain rule에서 사용됩니다. 이에 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mrow><mi>ϑ</mi><mi>l</mi><mi>o</mi><mi>s</mi><mi>s</mi></mrow><mrow><mi>ϑ</mi><mi>w</mi></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">{\\vartheta loss \\over \\vartheta w}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.2251079999999999em;vertical-align:-0.345em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8801079999999999em;\"><span style=\"top:-2.6550000000000002em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">ϑ</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02691em;\">w</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">ϑ</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathdefault mtight\">o</span><span class=\"mord mathdefault mtight\">s</span><span class=\"mord mathdefault mtight\">s</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span> 가 0이 되어 학습이 되지 않습니다.</li>\n<li>xavier initialization은 fan<em>in과 fan</em>out을 사용하며 tanh, sigmoid에 적용합니다. He initialization은 fan_in을 사용하며 ReLU에 적용합니다.</li>\n<li>He initialization은 Xavier initialization이 만들어주는 weight 분포의 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>σ</mi></mrow><annotation encoding=\"application/x-tex\">\\sigma</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">σ</span></span></span></span>(표준편차)보다 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msqrt><mn>2</mn></msqrt></mrow><annotation encoding=\"application/x-tex\">\\sqrt{2}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.04em;vertical-align:-0.13278em;\"></span><span class=\"mord sqrt\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.90722em;\"><span class=\"svg-align\" style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\" style=\"padding-left:0.833em;\"><span class=\"mord\">2</span></span></span><span style=\"top:-2.86722em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"hide-tail\" style=\"min-width:0.853em;height:1.08em;\"><svg width='400em' height='1.08em' viewBox='0 0 400000 1080' preserveAspectRatio='xMinYMin slice'><path d='M95,702\nc-2.7,0,-7.17,-2.7,-13.5,-8c-5.8,-5.3,-9.5,-10,-9.5,-14\nc0,-2,0.3,-3.3,1,-4c1.3,-2.7,23.83,-20.7,67.5,-54\nc44.2,-33.3,65.8,-50.3,66.5,-51c1.3,-1.3,3,-2,5,-2c4.7,0,8.7,3.3,12,10\ns173,378,173,378c0.7,0,35.3,-71,104,-213c68.7,-142,137.5,-285,206.5,-429\nc69,-144,104.5,-217.7,106.5,-221\nl0 -0\nc5.3,-9.3,12,-14,20,-14\nH400000v40H845.2724\ns-225.272,467,-225.272,467s-235,486,-235,486c-2.7,4.7,-9,7,-19,7\nc-6,0,-10,-1,-12,-3s-194,-422,-194,-422s-65,47,-65,47z\nM834 80h400000v40h-400000z'/></svg></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.13278em;\"><span></span></span></span></span></span></span></span></span>배 만큼 더 커서 <strong>activation value의 분포를 좌우로</strong> 더 늘려주게 됩니다.</li>\n</ol>\n<h2 id=\"reference\" style=\"position:relative;\"><a href=\"#reference\" aria-label=\"reference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Reference</h2>\n<ul>\n<li>Xavier intialization: <a href=\"https://reniew.github.io/13/\">https://reniew.github.io/13/</a></li>\n<li>Xavier initialization 설명 및 사진 인용: <a href=\"https://nittaku.tistory.com/269\">https://nittaku.tistory.com/269</a></li>\n<li>He initialization 설명 및 사진 인용: <a href=\"https://excelsior-cjh.tistory.com/m/177\">https://excelsior-cjh.tistory.com/m/177</a></li>\n</ul>","frontmatter":{"title":"Weight Initialization","date":"August 21, 2021"}}},"pageContext":{"slug":"/AI/weight-initialization/","previous":{"fields":{"slug":"/Mathematics/maximum-likelihood-estimation(mle)/"},"frontmatter":{"title":"Maximum Likelihood Estimation(MLE)"}},"next":null}},"staticQueryHashes":["2486386679","3128451518"]}