---
title: [Kaggle]Digit Recognizer
date: 2021-09-10 23:09:64
category: Competition
thumbnail: { thumbnailSrc }
draft: false
---

&nbsp; &nbsp; ì´ë²ˆ ì‹œê°„ì—ëŠ” Kaggle ì…ë¬¸ìë“¤ì´ Kaggleì„ ì‹œì‘í•  ë•Œ ë§ì´ í•´ë³´ëŠ” Digit-Recognizerì— ëŒ€í•´ ì´ì•¼ê¸° í•´ë³´ë ¤ê³  í•©ë‹ˆë‹¤!ğŸ˜Š ë§ì€ ì‚¬ëŒë“¤ì´ Kaggleì„ ì‹œì‘í•  ë•Œ ì´ competitionì— ì°¸ê°€í•´ë³´ê³  ë§ì€ notebookë“¤ì„ ë³´ë©´ì„œ ë”¥ëŸ¬ë‹ì´ë‚˜ ë¨¸ì‹ ëŸ¬ë‹ì´ ë¬´ì—‡ì´ê³  ì–´ë–»ê²Œ í•´ì•¼í•˜ëŠ”ì§€ ì•Œê²Œë˜ëŠ”ë°ìš”! Digit-Recognizerì€ **MNIST dataë¥¼ ë¶„ë¥˜**í•´ë³´ëŠ” ì…ë¬¸ììš© competitionì…ë‹ˆë‹¤. ì´ ëŒ€íšŒë¥¼ í•˜ë©´ì„œ **êµ¬í˜„ ê´€ì ì—ì„œ** ì•Œê²Œë˜ê±°ë‚˜ ëŠë‚€ì ì„ ë°”íƒ•ìœ¼ë¡œ í•´ë‹¹ í¬ìŠ¤íŠ¸ë¥¼ ì‘ì„±í•˜ê³ ì í•©ë‹ˆë‹¤. ì•„ë˜ëŠ” ì´ë²ˆ í¬ìŠ¤íŒ…ì˜ Categoryì…ë‹ˆë‹¤!

## Category

1. Code Description
2. History
3. Summary
4. Reference

## Code Description

## History

**â‘  version_1**

ì‚¬ìš©í•œ ArchitectureëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

4`conv`- `batch` - `relu` , 1`pooling`, 3`fc layers`

&nbsp; &nbsp; ë˜í•œ, **He initilizationm**ê³¼ **batch normalization**ì„ ì ìš©í•˜ì—¬ êµ¬í˜„ì„ í•˜ì˜€ìŠµë‹ˆë‹¤. **4ê°œì˜ convolution layer**ì™€ **batchnorm**, **reluë¥¼ ì ìš©**í•˜ì˜€ê³  **1ë²ˆì˜ poolingì„ ì‚¬ìš©**í–ˆìŠµë‹ˆë‹¤. ë˜í•œ **3ê°œì˜ fc layerë¥¼ ì‚¬ìš©**í•˜ê³  **2ê°œì˜ dropoutì„ ì ìš©**í–ˆìŠµë‹ˆë‹¤. ë˜í•œ **early-stopping ê¸°ë²•ì„ ì‚¬ìš©**í–ˆìŠµë‹ˆë‹¤.

&nbsp; &nbsp; ë˜í•œ **early stoppingì„ ì‚¬ìš©**í•˜ì—¬ **modelì´ training dataì— overfitting**ë˜ëŠ” ê²ƒì„ ë§‰ì•˜ìŠµë‹ˆë‹¤.

```python

#conv1->batch1->relu->conv2->batch2->relu->pool->conv3->batch3->relu->conv4->batch4->relu
#->fc1->relu->drop->fc2->relu->drop->fc3
class CNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(in_channels=1,  out_channels=16, kernel_size=3, stride=1)
        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1)
        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1)
        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1)

        self.fc1 = nn.Linear(128*8*8,1024)
        self.fc2 = nn.Linear(1024,512)
        self.fc3 = nn.Linear(512,10)

        self.batchnorm1 = nn.BatchNorm2d(16)
        self.batchnorm2 = nn.BatchNorm2d(32)
        self.batchnorm3 = nn.BatchNorm2d(64)
        self.batchnorm4 = nn.BatchNorm2d(128)
        self.drop = nn.Dropout2d(p=0.5)
        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)
        self.relu = nn.ReLU()

        #initilization
        nn.init.kaiming_normal_(self.conv1.weight, mode='fan_in', nonlinearity='relu')
        nn.init.kaiming_normal_(self.conv2.weight, mode='fan_in', nonlinearity='relu')
        nn.init.kaiming_normal_(self.conv3.weight, mode='fan_in', nonlinearity='relu')
        nn.init.kaiming_normal_(self.conv4.weight, mode='fan_in', nonlinearity='relu')
        nn.init.kaiming_normal_(self.fc1.weight, mode='fan_in', nonlinearity='relu')
        nn.init.kaiming_normal_(self.fc2.weight, mode='fan_in', nonlinearity='relu')
        nn.init.kaiming_normal_(self.fc3.weight, mode='fan_in', nonlinearity='relu')

def forward(self,x):
        #x shape: 64*1*28*28
        out = self.conv1(x)
        out = self.batchnorm1(out)
        out = self.relu(out)
        #64*16*26*26

        out = self.conv2(out)
        out = self.batchnorm2(out)
        out = self.relu(out)
        #64*32*24*24

        out = self.max_pool(out)
        #64*32*12*12

        out = self.conv3(out)
        out = self.batchnorm3(out)
        out = self.relu(out)
        #64*64*10*10

        out = self.conv4(out)
        out = self.batchnorm4(out)
        out = self.relu(out)
        #64*128*8*8
        #flatten
        out = out.view(out.size(0),-1)
        #64*128*8*8

        out = self.fc1(out)
        out = self.relu(out)
        out = self.drop(out)

        out = self.fc2(out)
        out = self.relu(out)
        out = self.drop(out)

        out = self.fc3(out)
```

**â‘  version_2**

1. data augmentation ì¶”ê°€

## Summary

1.  `transforms.ToPILImage()`ë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ìœ ëŠ” **csvíŒŒì¼ í˜•íƒœë¡œ ë°ì´í„°ì…‹**ì„ ë°›ì„ ê²½ìš°, ë°”ë¡œ `torch.Tensor`ë¡œ ë°”ê¿”ì¤„ ìˆ˜ ì—†ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤. `transforms.ToTensor()`ëŠ” `numpy.ndarray`ë‚˜ `PIL image`ë¥¼ **pytorch tensorë¡œ ë°”ê¿”ì£¼ê¸° ë•Œë¬¸**ì— **csvì—ì„œ ë°›ì€ dataframe**ì„ **PIL imageë¡œ ë°”ê¿”ì£¼ê³  ì´ PIL imageë¥¼ pytorch tensorë¡œ ë°”ê¿”ì£¼ì–´ì•¼**í•©ë‹ˆë‹¤. ì´ì— ì•„ë˜ì™€ ê°™ì´ ì‘ì„±í•©ë‹ˆë‹¤.

    ```python
    from torchvision import transforms

    transfrom = transforms.compose([
    				transforms.ToPILImage(),
    				transforms.ToTensor()
    ])
    ```

2.  dataë¥¼ ì–´ë–»ê²Œ transformì‹œí‚¬ì§€ëŠ” custom datasetì„ ì´ˆê¸°í™”ì‹œí‚¬ ë•Œ, ì¸ìë¡œ ë„£ì–´ì£¼ëŠ” ê²ƒì„ í”í•˜ê²Œ ë³¼ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤. ì•„ë˜ì˜ ê·¸ë¦¼ì²˜ëŸ¼ ë§ì´ì£ !ğŸ˜

    ```python
    class MNIST_data(Dataset):
    		def __init__(self,
    								 file_path,
    		             transform = transforms.Compose([transforms.ToPILImage(),
    														 transforms.ToTensor(),
    		                         transforms.Normalize(mean=(0.5,), std=(0.5,))])
    		              ):
    ```

3.  early stoppingì€ training setì— ëŒ€í•œ ì˜¤ë¥˜ê°€ ì¤„ì–´ë“¤ì§€ë§Œ validation setì— ëŒ€í•œ loss ì˜¬ë¼ê°€ê²Œ ë˜ë©´ ë©ˆì¶”ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤. **â‘  version_1**ì—ì„œ í•´ë‹¹ ê¸°ë²•ì„ ì¶”ê°€ì‹œì¼°ìŠµë‹ˆë‹¤.
4.  batchnormì´ë‘ dropoutì„ ì„ì–´ì“°ë©´ ì˜¤íˆë ¤ **ì„±ëŠ¥ì´ ì €í•˜**ëœë‹¤ê³  í•©ë‹ˆë‹¤ğŸ˜…
5.  `np.arange(1,len(test_data)+1)`ì„ í†µí•´ ì‰½ê²Œ csvì˜ columnì„ ë§Œë“¤ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤~!
6.  torchâ†’numpyë¡œ ë³€í™˜í•  ë• `. numpy()`ë¥¼, Dataframeâ†’numpyë¡œ ë³€í™˜í•  ë• `.values` ëŒ€ì‹ ì— `.to_numpy()`ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. `.values`ëŠ” **deprecate**(ë¹„ì¶”ì²œ!)í•œë‹¤ê³  í•˜ë”ë¼êµ¬ìš”!  
    ë˜í•œ, numpyë¥¼ torch.Tensorë¡œ ë°”ê¾¸ê¸° ìœ„í•´ì„  `torch.from_numpy()`ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ ê²½ìš°, **shapeëŠ” ìœ ì§€**í•œ ì±„ë¡œ **typeë§Œ ë³€í™˜**ë©ë‹ˆë‹¤!

    <p align="center">
    <img src="assets\2021-09-10\1.png"/>
    </p>

7.  matplolibì´ë‚˜ cv2ì˜ ê²½ìš°, `numpy.ndarray`ë¥¼ ë§ì´ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ ë•Œ, `numpy.ndarray`ë“¤ì˜ formatì€ HWCì¸ë° torch.Tensorì˜ ê²½ìš° CHWì˜ formatì„ ê°–ìŠµë‹ˆë‹¤. ë”°ë¼ì„œ HWCì¸ numpy.ndarrayë“¤ì„ CHW formatì„ ê°–ê³  ìˆëŠ” troch.Tensorë¡œ ë°”ê¿”ì£¼ê¸° ìœ„í•´ì„œ `torchvision.transfroms.ToTensor()`ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ë”°ë¼ì„œ, shapeë¥¼ ë°”ê¿”ì£¼ê¸° ìœ„í•´ì„  6.ì˜ `torch.from_numpy()`ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ì•„ë‹ˆë¼ `ToTensor()`ë¥¼ ì‚¬ìš©í•´ì•¼í•©ë‹ˆë‹¤.

    <p align="center">
        <img src="assets\2021-09-10\2.png"/>
    </p>

    ë˜í•œ ì•„ë˜ì™€ ê°™ì€ ë°©ë²•ìœ¼ë¡œ `torchvision.transfroms.ToTensor()`ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

    <p align="center">
        <img src="assets\2021-09-10\3.png"/>
    </p>

8.  `plt.scatter()`ì„ ì‚¬ìš©í•˜ë©´ **ì **ìœ¼ë¡œ, `plt.plot`ì„ ì‚¬ìš©í•˜ë©´ **ê·¸ë˜í”„**ë¡œ ê·¸ë ¤ì§‘ë‹ˆë‹¤!
9.  `cv2.imread`ëŠ” ì´ë¯¸ì§€ë¥¼ ë°›ì•„ `numpy.ndarray`ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤. ë”°ë¼ì„œ csvíŒŒì¼ì„ ì½ì„ ë•Œ, cv2ë¡œ imageë¥¼ ì½ì€ ë“¯í•œ íš¨ê³¼ë¥¼ ì£¼ê¸° ìœ„í•´ì„  pandasì˜ `read_csv`ë¥¼ ì‚¬ìš©í•˜ì—¬ DataFrameìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ì½ì€ í›„ `to_numpy()`ë¥¼ í†µí•´ `numpy.ndarray`ë¡œ ë°”ê¿”ì£¼ë©´ ë©ë‹ˆë‹¤. ì¦‰, í‰ìƒì‹œì— ì´ë¯¸ì§€ë¥¼ ì½ì„ ë•Œ `numpy.ndarray`ë¡œ ì½ìœ¼ë¯€ë¡œ DataFrameì„ ë°›ê²Œë˜ë©´ ì´ê²ƒ ë˜í•œ `numpy.ndarray`ë¡œ ë°”ê¿”ì„œ **data augmentation**(albumentationì„ í†µí•´)ì„ ìˆ˜í–‰í•˜ë©´ ë©ë‹ˆë‹¤. albumentationì„ ì‚¬ìš©í•  ê²½ìš°, `numpy.ndarray`
10. Albumentationì€ `cv2.imread`ë¥¼ í†µí•´ imageë¥¼ `numpy.ndarray`ë¡œ ì½ì–´ data augmentationì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. `cv2.imread`ë¥¼ í†µí•´ ì½ê²Œ ë˜ë©´ `HWC format`ì„ ê°€ì§„ `numpy.ndarray`ë¥¼ ë°›ê²Œ ë˜ëŠ”ë° Albumentationì€ `HWC format`ì„ ê°€ì§„ `numpy.ndarray`ë¥¼ ê·¸ëŒ€ë¡œ ë°›ì•„ **data augmentationì„ ìˆ˜í–‰**í•©ë‹ˆë‹¤. ë˜í•œ `matplotlib.pyplot.imshow()`ëŠ” argumentë¡œ `numpy.ndarray`ë¥¼ ë°›ëŠ”ë° ì´ ë–„ì˜ format ë˜í•œ `HWC format`ì´ ë©ë‹ˆë‹¤.
    ì¦‰, `Albumentations`, `matplotlib`, `cv2`ëŠ” `HWC format`ì„ ê°€ì§€ëŠ” `numpy.ndarray`ì„ ë‹¤ë£¹ë‹ˆë‹¤. ë”°ë¼ì„œ torch.Tensorì—ì„œì˜ ì´ë¯¸ì§€ëŠ” `CHW format`ì´ë¯€ë¡œ ìˆœì„œë¥¼ ë°”ê¿”ì¤˜ì•¼í•©ë‹ˆë‹¤. ì´ì—`torchvision.transfroms.ToTensor()`ì„ ì‚¬ìš©í•´ì•¼í•œë‹¤ê³  ë§í–ˆì—ˆì£ ?!ğŸ˜‰
11. `np.repeat(ndarray, ë°˜ë³µ íšŸìˆ˜, axis=)`ì„ í†µí•´ imageì°¨ì›ì„ ëŠ˜ë ¤ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. MNIST ë°ì´í„°ì˜ ê²½ìš° 1ì°¨ì›ì¼ ë• ì´ìƒí•œ ìƒ‰ì´ ë‚˜ì˜¤ê²Œ ë˜ì§€ë§Œ `image = np.repeat(image,3,axis=2)`ì„ ì‚¬ìš©í•´ì„œ 3ì°¨ì›ìœ¼ë¡œ ëŠ˜ë¦¬ê²Œ ë˜ë©´ ìµìˆ™í•œ í•˜ì–€ìƒ‰ ìˆ«ìê°€ ë‚˜ì˜¤ê²Œ ë©ë‹ˆë‹¤. ì•„ë˜ì˜ ê·¸ë¦¼ë“¤ ì²˜ëŸ¼ ì¶œë ¥ë˜ê²Œ ë©ë‹ˆë‹¤.

    <p align="center">
        <img src="assets\2021-09-10\4.png"/>
    </p>

    <p align="center">
        <img src="assets\2021-09-10\5.png"/>
    </p>

12. `import Albumentations.pytorch.transforms.ToTensor()`ë¥¼ í†µí•´ pytorch tensorë¡œ ë³€í™˜ê°€ëŠ¥í•©ë‹ˆë‹¤.
13. í•˜ë‚˜ì˜ datasetê°ì²´ ì•ˆì—ì„œ valid datsetê³¼ training datasetì„ ëª»ë‚˜ëˆ”. dataloaderë¥¼ í†µí•´ì„œ ë½‘ì•„ì¤„ ë°©ë²•ì´ ì—†ìŒ. ë°ì´í„°ë¥¼ ë‚˜ëˆ ë†”ë„ ë½‘ì•„ì˜¬ ë°©ë²•ì´ì—†ìŒ...

## Todo

- [ ] albumentationìœ¼ë¡œ augmentation ì „ì²˜ë¦¬í•´ë³´ê¸°
- [ ] vscodeë¡œ .pyë¡œ ë‚˜ëˆ ì„œ ëª¨ë¸ ëŒë ¤ë³´ê¸°
- [ ] Ray-tuneìœ¼ë¡œ Hyperparameter tuningí•´ë³´ê¸°
- [ ] ë‚´ì¥í•¨ìˆ˜ ì°¾ì•„ë³´ê¸° **len**, **getitem**
- [ ] image(matplotlibê³¼ Albumentationì€ numpy ë°°ì—´ê¸°ì¤€ìœ¼ë¡œ HWCë¡œ ì‘ë™í•¨ ì•„ë§ˆ cv2.imreadë„ HWCìˆœì„œëŒ€ë¡œ ì½ëŠ”ë“¯?)ëŠ” HWCìˆœì´ê³  pytorch tensorëŠ” CHWì¸ì§€ í™•ì¸í•˜ê¸°

## Reference

1. `transforms.ToPILImage()`ë¥¼ ì™œ ì‚¬ìš©í•˜ëŠ”ê°€?: [https://green-late7.tistory.com/56](https://green-late7.tistory.com/56)
2. numpy stack ë°©ë²•(concatenate): [https://rfriend.tistory.com/352](https://rfriend.tistory.com/352)
3. Reference notebook: [https://www.kaggle.com/juiyangchang/cnn-with-pytorch-0-995-accuracy/output](https://www.kaggle.com/juiyangchang/cnn-with-pytorch-0-995-accuracy/output)
4. albumentation vs torchvision: [https://pseudo-lab.github.io/Tutorial-Book/chapters/object-detection/Ch3-preprocessing.html](https://pseudo-lab.github.io/Tutorial-Book/chapters/object-detection/Ch3-preprocessing.html)
5. kaggle csvíŒŒì¼ ì œì¶œí•˜ê¸°: [https://wikidocs.net/92861](https://wikidocs.net/92861)
6. model ì €ì¥ ë° ë¶ˆëŸ¬ì˜¤ê¸°: [https://tutorials.pytorch.kr/beginner/saving_loading_models.html](https://tutorials.pytorch.kr/beginner/saving_loading_models.html)
7. early-stopping github code: [https://github.com/Bjarten/early-stopping-pytorch/blob/master/MNIST_Early_Stopping_example.ipynb](https://github.com/Bjarten/early-stopping-pytorch/blob/master/MNIST_Early_Stopping_example.ipynb)
8. score ì˜¬ë¦¬ëŠ” ë²•:[https://wegonnamakeit.tistory.com/9](https://wegonnamakeit.tistory.com/9)
9. `DataFrame.to_numpy()`: [https://stackoverflow.com/questions/13187778/convert-pandas-dataframe-to-numpy-array/](https://stackoverflow.com/questions/13187778/convert-pandas-dataframe-to-numpy-array/)
10. `plt.subplots(nrows=,ncols=,figsize=)`ì‚¬ìš©ë²•: [https://matplotlib.org/stable/api/\_as_gen/matplotlib.pyplot.subplots.html](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.subplots.html)
11. `np.repeat()`: [https://numpy.org/doc/stable/reference/generated/numpy.repeat.html](https://numpy.org/doc/stable/reference/generated/numpy.repeat.html)
12. image augmentation using albumentation youtube: [https://www.youtube.com/watch?v=n_f6d4bPFME](https://www.youtube.com/watch?v=n_f6d4bPFME)
13. albumentation probability in One of Block and description about it: [https://albumentations.readthedocs.io/en/latest/probabilities.html](https://albumentations.readthedocs.io/en/latest/probabilities.html)
14. albumentation ê°„ë‹¨ ì†Œê°œ: [https://hoya012.github.io/blog/albumentation_tutorial/](https://hoya012.github.io/blog/albumentation_tutorial/)
15. albumentation documentation example: [https://albumentations.ai/docs/examples/example/#Import-the-required-libraries](https://albumentations.ai/docs/examples/example/#Import-the-required-libraries)
16. torchvision.transforms vs albumentation: [https://pseudo-lab.github.io/Tutorial-Book/chapters/object-detection/Ch3-preprocessing.html](https://pseudo-lab.github.io/Tutorial-Book/chapters/object-detection/Ch3-preprocessing.html)
17. albumentation ìì„¸í•œ ì†Œê°œ: [https://ichi.pro/ko/albumentation-sijaghagi-pytorch-yejeeseo-dib-leoning-imiji-hwagdae-gibeob-hoegdeug-78798591550456](https://ichi.pro/ko/albumentation-sijaghagi-pytorch-yejeeseo-dib-leoning-imiji-hwagdae-gibeob-hoegdeug-78798591550456)
18. albumentation.pytorch.ToTensorV2 documentation: [https://albumentations.ai/docs/api_reference/pytorch/transforms/](https://albumentations.ai/docs/api_reference/pytorch/transforms/)
